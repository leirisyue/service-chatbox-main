
import json
import os
import time
import uuid
from typing import Dict, List

import psycopg2
from fastapi import (APIRouter, File, Form, UploadFile)
from historiesapi import histories
from PIL import Image
from psycopg2.extras import RealDictCursor

from .textfunc import call_gemini_with_retry,format_suggested_prompts
from .textapi_qwen import generate_suggested_prompts, search_products
from config import settings

from chatapi.connect_db import get_db

router = APIRouter()
# ================================================================================================
# FUNCTION DEFINITIONS
# ================================================================================================
    
def batch_classify_materials(materials_batch: List[Dict]) -> List[Dict]:
    if not materials_batch:
        return []
    
    
    materials_text = ""
    for i, mat in enumerate(materials_batch, 1):
        materials_text += f"{i}. ID: {mat['id_sap']}, T√™n: {mat['name']}\n"
    
    prompt = f"""
                Ph√¢n lo·∫°i {len(materials_batch)} nguy√™n v·∫≠t li·ªáu n·ªôi th·∫•t:
                {materials_text}
                X√°c ƒë·ªãnh:
                1. material_group: G·ªó, Da, V·∫£i, ƒê√°, Kim lo·∫°i, K√≠nh, Nh·ª±a, S∆°n, Keo, Ph·ª• ki·ªán, Kh√°c
                2. material_subgroup: Nh√≥m con c·ª• th·ªÉ (VD: "G·ªó t·ª± nhi√™n", "Da th·∫≠t", "V·∫£i cao c·∫•p")
                OUTPUT JSON ARRAY ONLY:
                [
                    {{"id_sap": "M001", "material_group": "...", "material_subgroup": "..."}},
                    {{"id_sap": "M002", "material_group": "...", "material_subgroup": "..."}}
                ]
            """
    
    # Call Gemini with retry
    response_text = call_gemini_with_retry( prompt, max_retries=3)
    
    # Create default results (Fallback) to return if AI fails
    default_results = [{
        'id_sap': m['id_sap'],
        'material_group': 'Not classified',
        'material_subgroup': 'Not classified'
    } for m in materials_batch]

    if not response_text:
        return default_results
    
    try:
        clean = response_text.strip()
        # Clean markdown JSON
        if "```json" in clean:
            clean = clean.split("```json")[1].split("```")[0].strip()
        elif "```" in clean:
            clean = clean.split("```")[1].split("```")[0].strip()
        
        results = json.loads(clean)
        
        # Check if number of results matches input
        if len(results) != len(materials_batch):
            print(f"WARNING: Batch materials mismatch: expected {len(materials_batch)}, got {len(results)}")
            return default_results
        
        return results
        
    except Exception as e:
        print(f"ERROR: Batch materials classification error: {e}")
        return default_results

def batch_classify_products(products_batch: List[Dict]) -> List[Dict]:
    if not products_batch:
        return []

    
    # Create product list in prompt
    products_text = ""
    for i, prod in enumerate(products_batch, 1):
        products_text += f"{i}. ID: {prod['id_sap']}, Name: {prod['name']}\n"
    
    prompt = f"""
            B·∫°n l√† chuy√™n gia ph√¢n lo·∫°i s·∫£n ph·∫©m n·ªôi th·∫•t cao c·∫•p.
            Ph√¢n lo·∫°i {len(products_batch)} s·∫£n ph·∫©m sau:
            {products_text}
            M·ªói s·∫£n ph·∫©m c·∫ßn ph√¢n lo·∫°i theo:
            1. category: B√†n, Gh·∫ø, Sofa, T·ªß, Gi∆∞·ªùng, ƒê√®n, K·ªá, B√†n l√†m vi·ªác, Kh√°c
            2. sub_category: Danh m·ª•c ph·ª• c·ª• th·ªÉ (VD: "B√†n ƒÉn", "Gh·∫ø bar", "Sofa g√≥c"...)
            3. material_primary: G·ªó, Da, V·∫£i, Kim lo·∫°i, ƒê√°, K√≠nh, Nh·ª±a, M√¢y tre, H·ªón h·ª£p
            OUTPUT JSON ARRAY ONLY (no markdown, no backticks):
            [
                {{"id_sap": "SP001", "category": "...", "sub_category": "...", "material_primary": "..."}},
                {{"id_sap": "SP002", "category": "...", "sub_category": "...", "material_primary": "..."}}
            ]
    """
    
    # Call AI with retry logic
    response_text = call_gemini_with_retry( prompt, max_retries=3)
    
    # Default fallback if AI completely fails
    default_results = [{
        'id_sap': p['id_sap'],
        'category': 'Ch∆∞a ph√¢n lo·∫°i',
        'sub_category': 'Ch∆∞a ph√¢n lo·∫°i',
        'material_primary': 'Ch∆∞a x√°c ƒë·ªãnh'
    } for p in products_batch]

    if not response_text:
        return default_results
    
    try:
        clean = response_text.strip()
        # Handle case when Gemini returns markdown code block
        if "```json" in clean:
            clean = clean.split("```json")[1].split("```")[0].strip()
        elif "```" in clean:
            clean = clean.split("```")[1].split("```")[0].strip()
        
        results = json.loads(clean)
        
        # Ensure result count matches input
        if len(results) != len(products_batch):
            print(f"WARNING: Batch size mismatch: expected {len(products_batch)}, got {len(results)}")
            return default_results
        
        return results
        
    except Exception as e:
        print(f"ERROR: Batch classification parse error: {e}")
        return default_results

# ================================================================================================
# API ENDPOINTS
# ================================================================================================
@router.post("/search-image", tags=["Classifyapi"])
async def search_by_image(
    file: UploadFile = File(...),
    session_id: str = Form(default=str(uuid.uuid4()))
):
    file_path = f"./media/temp_{uuid.uuid4()}.jpg"
    try:
        # Read file content
        contents = await file.read()
        
        # Save to temporary file
        with open(file_path, "wb") as buffer:
            buffer.write(contents)
        
        # Open image using PIL
        img = Image.open(file_path)
        
        prompt = """
            ROLE
            You are a Senior Interior Materials Analyst at AA Corporation. You have deep knowledge of materials, construction, and interior design styles.

            TASK
            Analyze the provided image and extract technical information into a standard JSON Array format for input into the database search system.

            CHI·∫æN L∆Ø·ª¢C D·ªÆ LI·ªÜU (DATA STRATEGY)
            Output ph·∫£i l√† m·ªôt m·∫£ng ch·ª©a ch√≠nh x√°c 2 ƒë·ªëi t∆∞·ª£ng (objects) nh·∫±m ph·ª•c v·ª• c∆° ch·∫ø t√¨m ki·∫øm ƒëa t·∫ßng:

            Object 1 (∆Øu ti√™n): T√¨m ki·∫øm ch√≠nh x√°c (Exact Match). T·ª´ kh√≥a ph·∫£i m√¥ t·∫£ c·ª• th·ªÉ ƒë·∫∑c t√≠nh n·ªïi b·∫≠t nh·∫•t c·ªßa s·∫£n ph·∫©m, bao g·ªìm h√¨nh th√°i v√† c√¥ng d·ª•ng.

            Object 2 (D·ª± ph√≤ng): T√¨m ki·∫øm m·ªü r·ªông (Broad Match). T·ª´ kh√≥a l√† danh m·ª•c chung ho·∫∑c t·ª´ ƒë·ªìng nghƒ©a ƒë·ªÉ ƒë·∫£m b·∫£o k·∫øt qu·∫£ t√¨m ki·∫øm kh√¥ng b·ªã r·ªóng n·∫øu t√¨m ch√≠nh x√°c th·∫•t b·∫°i.

            H∆Ø·ªöNG D·∫™N C√ÅC TR∆Ø·ªúNG (FIELDS)
            category: Ch·ªâ ch·ªçn 1 danh m·ª•c ch√≠nh x√°c nh·∫•t (VD: Gh·∫ø, B√†n, Sofa, T·ªß, ƒê√®n...).

            visual_description: Vi·∫øt ƒëo·∫°n vƒÉn m√¥ t·∫£ chuy√™n nghi·ªáp (catalogue). T·∫≠p trung: c·∫•u tr√∫c khung, ch·∫•t li·ªáu b·ªÅ m·∫∑t, t√≠nh nƒÉng v√† c·∫£m gi√°c s·ª≠ d·ª•ng. (N·ªôi dung n√†y gi·ªëng nhau ·ªü c·∫£ 2 object).

            search_keywords:

            T·∫°i Object 1: Tr√≠ch xu·∫•t t·ª´ kh√≥a "ng√°ch" c·ª• th·ªÉ, m√¥ t·∫£ chi ti·∫øt (VD: "gh·∫ø xoay l∆∞·ªõi", "sofa da b√≤", "b√†n ƒÉn m·∫∑t ƒë√°", "gh·∫ø vƒÉn ph√≤ng c√¥ng th√°i h·ªçc",...).

            T·∫°i Object 2: Tr√≠ch xu·∫•t t·ª´ kh√≥a "g·ªëc" ph·ªï bi·∫øn (VD: "gh·∫ø vƒÉn ph√≤ng", "sofa ph√≤ng kh√°ch", "b√†n ƒÉn",..).

            material_detected: Li·ªát k√™ v·∫≠t li·ªáu nh√¨n th·∫•y, ngƒÉn c√°ch b·∫±ng d·∫•u ph·∫©y. ∆Øu ti√™n t·ª´ chuy√™n ng√†nh (Nh·ª±a PP, Th√©p m·∫° chrome, V·∫£i n·ªâ...).

            color_tone: M√†u s·∫Øc ch·ªß ƒë·∫°o (T·ªëi ƒëa 2 m√†u).

            ƒê·ªäNH D·∫†NG OUTPUT (CONSTRAINTS)
            B·∫Øt bu·ªôc tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng m·∫£ng JSON: [ {...}, {...} ].

            Kh√¥ng bao b·ªçc b·ªüi markdown (json ... ).

            Kh√¥ng th√™m l·ªùi d·∫´n hay gi·∫£i th√≠ch.

            Ng√¥n ng·ªØ: Ti·∫øng Vi·ªát.

            V√ç D·ª§ M·∫™U (ONE-SHOT EXAMPLE)
            Input: [H√¨nh ·∫£nh m·ªôt chi·∫øc gh·∫ø vƒÉn ph√≤ng l∆∞·ªõi ƒëen ch√¢n xoay] Output: [ { "category": "Gh·∫ø", "visual_description": "Gh·∫ø xoay vƒÉn ph√≤ng l∆∞ng trung, thi·∫øt k·∫ø khung nh·ª±a ƒë√∫c nguy√™n kh·ªëi k·∫øt h·ª£p l∆∞ng l∆∞·ªõi tho√°ng kh√≠. Tay v·ªãn nh·ª±a c·ªë ƒë·ªãnh d·∫°ng v√≤m. ƒê·ªám ng·ªìi b·ªçc v·∫£i l∆∞·ªõi x·ªëp √™m √°i. Ch√¢n gh·∫ø sao 5 c√°nh b·∫±ng th√©p m·∫° chrome s√°ng b√≥ng, c√≥ b√°nh xe di chuy·ªÉn v√† c·∫ßn g·∫°t ƒëi·ªÅu ch·ªânh ƒë·ªô cao.", "search_keywords": "gh·∫ø xoay l∆∞·ªõi", "material_detected": "L∆∞·ªõi, Nh·ª±a PP, Th√©p m·∫° chrome, V·∫£i, M√∫t", "color_tone": "ƒêen, B·∫°c" }, { "category": "Gh·∫ø", "visual_description": "Gh·∫ø xoay vƒÉn ph√≤ng l∆∞ng trung, thi·∫øt k·∫ø khung nh·ª±a ƒë√∫c nguy√™n kh·ªëi k·∫øt h·ª£p l∆∞ng l∆∞·ªõi tho√°ng kh√≠. Tay v·ªãn nh·ª±a c·ªë ƒë·ªãnh d·∫°ng v√≤m. ƒê·ªám ng·ªìi b·ªçc v·∫£i l∆∞·ªõi x·ªëp √™m √°i. Ch√¢n gh·∫ø sao 5 c√°nh b·∫±ng th√©p m·∫° chrome s√°ng b√≥ng, c√≥ b√°nh xe di chuy·ªÉn v√† c·∫ßn g·∫°t ƒëi·ªÅu ch·ªânh ƒë·ªô cao.", "search_keywords": "gh·∫ø vƒÉn ph√≤ng", "material_detected": "L∆∞·ªõi, Nh·ª±a PP, Th√©p m·∫° chrome, V·∫£i, M√∫t", "color_tone": "ƒêen, B·∫°c" } ]

            B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH H√åNH ·∫¢NH N√ÄY
        """
        
        response = model.generate_content([prompt, img])
        
        # print("response Image analysis response:", response)
        
        if not response.text:
            return {
                "response": "‚ö†Ô∏è Kh√¥ng ph√¢n t√≠ch ƒë∆∞·ª£c ·∫£nh. Vui l√≤ng th·ª≠ ·∫£nh kh√°c.",
                "products": []
            }
        
        clean = response.text.strip()
        
        if "```json" in clean:
            
            clean = clean.split("```json")[1].split("```")[0].strip()
        elif "```" in clean:
            clean = clean.split("```")[1].split("```")[0].strip()
        
        try:
            ai_result = json.loads(clean)
        except json.JSONDecodeError as e:
            print(f"JSON Parse Error: {e}")
            ai_result = {
                "visual_description": clean[:200],
                "search_keywords": "",
                "category": "N·ªôi th·∫•t"
            }
        
        print(f"INFO: AI Image Analysis Result: {ai_result}")
        # Get search_keywords and shorten if too long
        search_keywords = ai_result[0].get("search_keywords", "").strip()
        category = ai_result[0].get("category", "")
        
        # If search_keywords too long (>50 chars) or empty, use category
        if not search_keywords or len(search_keywords) > 50:
            search_text = category  # Only use simplest category
            print(f"INFO: Using category as search term: {search_text}")
        else:
            # Get max first 3 words of search_keywords
            words = search_keywords.split()[:3]
            search_text = " ".join(words)
            print(f"INFO: Using simplified keywords: {search_text}")
        
        # Get secondary keywords from ai_result[1] if available (for better matching)
        secondary_keywords = ""
        secondary_category = ""
        secondary_material = ""
        
        if len(ai_result) > 1:
            secondary_keywords = ai_result[1].get("search_keywords", "").strip()
            secondary_category = ai_result[1].get("category", "")
            secondary_material = ai_result[1].get("material_detected", "")
            print(f"INFO: Using secondary keywords from AI: {secondary_keywords}")
        
        # ========== PARALLEL SEARCH WITH BOTH MAIN & SECONDARY KEYWORDS ==========
        params = {
            "category": category,
            "keywords_vector": search_text,  # EXTREMELY simple keywords
            "material_primary": ai_result[0].get("material_detected"),
            "main_keywords": ai_result[0].get("search_keywords"),
            "secondary_keywords": secondary_keywords,
            "secondary_category": secondary_category,
            "secondary_material": secondary_material,
        }
        
        print(f"INFO: Parallel search - Main: {ai_result[0].get('search_keywords')}, Secondary: {secondary_keywords}")
        
        # Disable automatic fallback in search_products, we handle dual search here
        search_result = search_products(params, session_id=session_id, disable_fallback=True)
        
        products = search_result.get("products", [])
        products_second = search_result.get("products_second", [])
        
        # Handle case when search_products returns None or empty
        if products is None:
            products = []
        if products_second is None:
            products_second = []
        
        print(f"INFO: Parallel search results - Products: {len(products)}, Products second: {len(products_second)}")
        
        # ========== IMAGE MATCHING VALIDATION ==========
        # Products already have base_score from parallel search, just apply image matching validation
        ai_interpretation = ai_result[0].get("visual_description", "").lower()
        
        for product in products:
            product_name = (product.get('product_name') or '').lower()
            category_prod = (product.get('category') or '').lower()
            
            # Check if name or category is in ai_interpretation
            name_match = any(word in ai_interpretation for word in product_name.split() if len(word) > 2)
            category_match = category_prod in ai_interpretation
            
            # If no match ‚Üí deduct base_score
            if not name_match and not category_match:
                current_score = product.get('base_score', 0.6)
                penalty = 0.25  # Deduct 0.25 points
                product['base_score'] = max(0, current_score - penalty)
                product['image_mismatch'] = True
                product['penalty_applied'] = penalty
                print(f"  ‚ö†Ô∏è Image mismatch penalty for {product.get('headcode')}: {current_score:.3f} -> {product['base_score']:.3f}")
            else:
                product['image_mismatch'] = False
        
        # # Apply same validation for products_second if they exist
        # if products_second and len(ai_result) > 1:
        #     ai_interpretation_second = ai_result[1].get("visual_description", "").lower()
            
        #     for product in products_second:
        #         product_name = (product.get('product_name') or '').lower()
        #         category_prod = (product.get('category') or '').lower()
                
        #         name_match = any(word in ai_interpretation_second for word in product_name.split() if len(word) > 2)
        #         category_match = category_prod in ai_interpretation_second
                
        #         if not name_match and not category_match:
        #             current_score = product.get('base_score', 0.5)
        #             penalty = 0.25
        #             product['base_score'] = max(0, current_score - penalty)
        #             product['image_mismatch'] = True
        #             product['penalty_applied'] = penalty
        #             print(f"  ‚ö†Ô∏è Image mismatch penalty (2nd) for {product.get('headcode')}: {current_score:.3f} -> {product['base_score']:.3f}")
        #         else:
        #             product['image_mismatch'] = False
        
        print(f"\nINFO: Image search completed. Total Products: found: {products:}\n")
        print(f"\nINFO: Image search completed. Total Products second: found: {products_second:}\n")
        # Classify products by base_score
        products_main = [p for p in products if p.get('final_score', 0) >= 0.75]
        products_low_confidence = [p for p in products if p.get('similarity', 0) < 0.6]
        products_second_main = [p for p in products_second if p.get('similarity', 0) >= 0.6 and p.get('final_score', 0) < 0.75] if products_second else []
        
        print(f"INFO: Image search - Main products: {len(products_main)}, Products second: {len(products_second_main)}, Low confidence: {len(products_low_confidence)}")
        
        histories.save_chat_to_histories(
            email="test@gmail.com",
            session_id=session_id,
            question="[IMAGE_UPLOAD]",
            answer=f"Ph√¢n t√≠ch ·∫£nh: {ai_result[0].get('visual_description', 'N/A')[:100]}... | T√¨m th·∫•y {len(products_main)} s·∫£n ph·∫©m theo y√™u c·∫ßu c·ªßa b·∫°n, {len(products_second_main)} s·∫£n ph·∫©m ph·ª•"
        )
        response_msg = ""
        # Build response message based on results
        if products_main or products_second_main:
            response_msg = f"üìã **Ph√¢n t√≠ch ·∫£nh:** T√¥i nh·∫≠n th·∫•y ƒë√¢y l√† **{ai_result[0].get('visual_description', 's·∫£n ph·∫©m')}**.\n\n"
            if products_main:
                response_msg += f"‚úÖ D·ª±a tr√™n h√¨nh ·∫£nh b·∫°n ƒë√£ t·∫£i l√™n, t√¥i c√≥ **{len(products_main)} s·∫£n ph·∫©m theo y√™u c·∫ßu c·ªßa b·∫°n** g·ª£i √Ω cho b·∫°n"
            # if products_second_main:
            #     response_msg += f"{', v√† ' if products_main else '‚úÖ T√¥i c√≥ '}**{len(products_second_main)} s·∫£n ph·∫©m t∆∞∆°ng t·ª±** v·ªõi y√™u c·∫ßu tr√™n c·ªßa b·∫°n! B·∫°n c√≥ th·ªÉ tham kh·∫£o"
            # response_msg += ":"
        if not products_main and products_second_main:
            response_msg = f"üìã **Ph√¢n t√≠ch ·∫£nh:** T√¥i nh·∫≠n th·∫•y ƒë√¢y l√† **{ai_result[0].get('visual_description', 's·∫£n ph·∫©m n·ªôi th·∫•t')}**.\n\n"
            response_msg += f"‚ö†Ô∏è R·∫•t ti·∫øc, t√¥i ch∆∞a t√¨m th·∫•y s·∫£n ph·∫©m ho√†n to√†n ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n trong c∆° s·ªü d·ªØ li·ªáu.\n\n" 
            # response_msg += f"‚úÖ Tuy nhi√™n, t√¥i c√≥ **{len(products_second_main)} s·∫£n ph·∫©m t∆∞∆°ng t·ª±** v·ªõi y√™u c·∫ßu c·ªßa b·∫°n! B·∫°n c√≥ th·ªÉ tham kh·∫£o:"
        else:
            response_msg = f"üìã **Ph√¢n t√≠ch ·∫£nh:** T√¥i nh·∫≠n th·∫•y ƒë√¢y l√† **{ai_result[0].get('visual_description', 's·∫£n ph·∫©m n·ªôi th·∫•t')}**.\n\n"
            response_msg += f"üíî  Th·∫≠t xin l·ªói t√¥i kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n trong c∆° s·ªü d·ªØ li·ªáu.\n"
            response_msg = f"üìã **Ph√¢n t√≠ch ·∫£nh:** T√¥i nh·∫≠n th·∫•y ƒë√¢y l√† **{ai_result[0].get('visual_description', 's·∫£n ph·∫©m n·ªôi th·∫•t')}**.\n\n" \
                            f"üíî  Th·∫≠t xin l·ªói, r·∫•t ti·∫øc t√¥i kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n.\n\n" \
                            f"‚≠ê **Ghi ch√∫**: B·∫°n c√≥ th·ªÉ m√¥ t·∫£ chi ti·∫øt h∆°n. Ho·∫∑c b·∫°n c√≥ th·ªÉ t√¨m s·∫£n ph·∫©m kh√°c. T√¥i s·∫Ω g·ª£i √Ω cho b·∫°n danh s√°ch s·∫£n ph·∫©m"

        tmp = generate_suggested_prompts(
                        "search_product_not_found",
                        {"query": "T√¨m s·∫£n ph·∫©m trong ·∫£nh"}
                    )
        suggested_prompts_mess = format_suggested_prompts(tmp)
        return {
            "response": response_msg,
            "products": products_main if products_main else None,
            "products_second": products_second_main if products_second_main else None,
            "productLowConfidence": products_low_confidence[:5] if products_low_confidence else [],
            "ai_interpretation": ai_result[0].get("visual_description", ""),
            "search_method": "image_vector_dual_search",
            "confidence_summary": {
                "products_main_count": len(products_main),
                "products_second_count": len(products_second_main),
                "low_confidence": len(products_low_confidence)
            },
            "success": True,
            "suggested_prompts_mess": suggested_prompts_mess
        }
    
    except Exception as e:
        print(f"ERROR: Image search error: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            "response": f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω ·∫£nh: {str(e)}. Vui l√≤ng th·ª≠ l·∫°i.",
            "products": [],
            "success": False,
        }
    
    finally:
        if os.path.exists(file_path):
            try:
                os.remove(file_path)
            except:
                pass

@router.post("/classify-products", tags=["Classifyapi"])
def classify_pending_products():
    try:
        conn = get_db()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # Get unclassified products
        cur.execute("""
            SELECT headcode, id_sap, product_name 
            FROM products_qwen 
            WHERE category = 'Ch∆∞a ph√¢n lo·∫°i' 
                OR sub_category = 'Ch∆∞a ph√¢n lo·∫°i'
                OR material_primary = 'Ch∆∞a x√°c ƒë·ªãnh'
            LIMIT 100
        """)
        
        pending_products = cur.fetchall()
        
        if not pending_products:
            conn.close()
            return {
                "message": "‚úÖ T·∫•t c·∫£ s·∫£n ph·∫©m ƒë√£ ƒë∆∞·ª£c ph√¢n lo·∫°i!",
                "classified": 0,
                "total": 0,
                "remaining": 0
            }
        
        total_pending = len(pending_products)
        classified = 0
        errors = []
        
        BATCH_SIZE = 8  # Gemini handles well with 5-10 items
        
        for i in range(0, len(pending_products), BATCH_SIZE):
            batch = pending_products[i:i+BATCH_SIZE]
            
            # Prepare input for batch classification
            batch_input = [{
                'id_sap': p['id_sap'],
                'name': p['product_name']
            } for p in batch]
            
            print(f"INFO: Classifying batch {i//BATCH_SIZE + 1} ({len(batch)} products)...")
            
            try:
                # CALL BATCH CLASSIFICATION
                results = batch_classify_products(batch_input)
                
                # Update to DB
                for j, result in enumerate(results):
                    try:
                        cur.execute("""
                            UPDATE products_qwen 
                            SET category = %s,
                                sub_category = %s,
                                material_primary = %s,
                                updated_at = NOW()
                            WHERE headcode = %s
                        """, (
                            result['category'],
                            result['sub_category'],
                            result['material_primary'],
                            batch[j]['headcode']
                        ))
                        classified += 1
                    except Exception as e:
                        errors.append(f"{batch[j]['headcode']}: {str(e)[:50]}")
                conn.commit()
                # Delay between batches to avoid rate limit
                if i + BATCH_SIZE < len(pending_products):
                    time.sleep(4)
                
            except Exception as e:
                print(f"ERROR: Batch {i//BATCH_SIZE + 1} failed: {e}")
                errors.append(f"Batch {i//BATCH_SIZE + 1}: {str(e)[:100]}")
                # Continue with next batch
                continue
        
        conn.close()
        
        # Check how many remain unclassified
        conn = get_db()
        cur = conn.cursor()
        cur.execute("""
            SELECT COUNT(*) FROM products_qwen 
            WHERE category = 'Ch∆∞a ph√¢n lo·∫°i' 
            OR sub_category = 'Ch∆∞a ph√¢n lo·∫°i'
            OR material_primary = 'Ch∆∞a x√°c ƒë·ªãnh'
        """)
        remaining = cur.fetchone()[0]
        conn.close()
        
        return {
            "message": f"‚úÖ ƒê√£ ph√¢n lo·∫°i {classified}/{total_pending} s·∫£n ph·∫©m",
            "classified": classified,
            "total": total_pending,
            "remaining": remaining,
            "errors": errors[:10] if errors else []
        }
        
    except Exception as e:
        return {
            "message": f"‚ùå L·ªói: {str(e)}",
            "classified": 0,
            "total": 0,
            "remaining": 0
        }

@router.post("/classify-materials", tags=["Classifyapi"])
def classify_pending_materials():
    """
    ü§ñ Ph√¢n lo·∫°i H√ÄNG LO·∫†T c√°c v·∫≠t li·ªáu ch∆∞a ph√¢n lo·∫°i
    """
    try:
        conn = get_db()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        cur.execute(f"""
            SELECT id_sap, material_name, material_group
            FROM {settings.MATERIALS_TABLE} 
            WHERE material_subgroup = 'Ch∆∞a ph√¢n lo·∫°i'
            LIMIT 100
        """)
        
        pending_materials = cur.fetchall()
        
        if not pending_materials:
            conn.close()
            return {
                "message": "‚úÖ T·∫•t c·∫£ v·∫≠t li·ªáu ƒë√£ ƒë∆∞·ª£c ph√¢n lo·∫°i!",
                "classified": 0,
                "total": 0,
                "remaining": 0
            }
        
        total_pending = len(pending_materials)
        classified = 0
        errors = []
        
        BATCH_SIZE = 10
        
        for i in range(0, len(pending_materials), BATCH_SIZE):
            batch = pending_materials[i:i+BATCH_SIZE]
            
            batch_input = [{
                'id_sap': m['id_sap'],
                'name': m['material_name']
            } for m in batch]
            
            print(f"BOT: Classifying materials batch {i//BATCH_SIZE + 1} ({len(batch)} items)...")
            
            try:
                results = batch_classify_materials(batch_input)
                
                for j, result in enumerate(results):
                    try:
                        cur.execute("""
                            UPDATE materials 
                            SET material_subgroup = %s,
                                updated_at = NOW()
                            WHERE id_sap = %s
                        """, (
                            result['material_subgroup'],
                            batch[j]['id_sap']
                        ))
                        classified += 1
                    except Exception as e:
                        errors.append(f"{batch[j]['id_sap']}: {str(e)[:50]}")
                
                conn.commit()
                
                if i + BATCH_SIZE < len(pending_materials):
                    time.sleep(4)
                
            except Exception as e:
                print(f"ERROR: Materials batch {i//BATCH_SIZE + 1} failed: {e}")
                errors.append(f"Batch {i//BATCH_SIZE + 1}: {str(e)[:100]}")
                continue
        
        conn.close()
        
        conn = get_db()
        cur = conn.cursor()
        cur.execute(f"""
            SELECT COUNT(*) FROM {settings.MATERIALS_TABLE} 
            WHERE material_subgroup = 'Ch∆∞a ph√¢n lo·∫°i'
        """)
        remaining = cur.fetchone()[0]
        conn.close()
        
        return {
            "message": f"‚úÖ ƒê√£ ph√¢n lo·∫°i {classified}/{total_pending} v·∫≠t li·ªáu",
            "classified": classified,
            "total": total_pending,
            "remaining": remaining,
            "errors": errors[:10] if errors else []
        }
        
    except Exception as e:
        return {
            "message": f"‚ùå L·ªói: {str(e)}",
            "classified": 0,
            "total": 0,
            "remaining": 0
        }

@router.post("/search-image-with-text", tags=["Classifyapi"])
async def search_by_image_with_text(
    file: UploadFile = File(...),
    description: str = Form(...),
    session_id: str = Form(default=str(uuid.uuid4()))
):
    file_path = f"./media/temp_{uuid.uuid4()}.jpg"
    try:
        # Read and save uploaded file
        contents = await file.read()
        with open(file_path, "wb") as buffer:
            buffer.write(contents)
        
        # Open image with PIL
        img = Image.open(file_path)
        
        # ========== DETECT SEARCH MODE (PRODUCT vs MATERIAL) ==========
        description_lower = description.lower()
        is_material_search = any(keyword in description_lower for keyword in [
            "v·∫≠t li·ªáu", "nguy√™n li·ªáu", "ch·∫•t li·ªáu", "material", 
            "g·ªó", "da", "v·∫£i", "kim lo·∫°i", "ƒë√°", "k√≠nh", "nh·ª±a"
        ])
        is_product_search = any(keyword in description_lower for keyword in [
            "s·∫£n ph·∫©m", "product", "b√†n", "gh·∫ø", "t·ªß", "gi∆∞·ªùng", "sofa", "ƒë√®n", "k·ªá"
        ])
        
        # If both or neither detected, default to product search
        if is_material_search and not is_product_search:
            search_mode = "material"
            print(f"INFO: Detected MATERIAL search mode from description: {description}")
        else:
            search_mode = "product"
            print(f"INFO: Detected PRODUCT search mode from description: {description}")
        
        # ========== PREPARE AI PROMPT BASED ON SEARCH MODE ==========
        if search_mode == "material":
            # MATERIAL SEARCH PROMPT
            prompt = f"""
                ROLE
                You are a Senior Materials Analyst at AA Corporation specializing in interior materials identification.

                TASK
                Analyze the provided image to identify and extract MATERIALS used in the product shown.

                USER'S DESCRIPTION & REQUIREMENTS:
                {description}

                CHI·∫æN L∆Ø·ª¢C D·ªÆ LI·ªÜU (DATA STRATEGY)
                Focus on identifying MATERIALS in the image, NOT products.
                Output must be an array with exactly 2 objects:

                Object 1 (Primary): Most specific material identification
                Object 2 (Fallback): Broader material category

                H∆Ø·ªöNG D·∫™N C√ÅC TR∆Ø·ªúNG (FIELDS)
                material_group: Main material group (G·ªó, Da, V·∫£i, Kim lo·∫°i, ƒê√°, K√≠nh, Nh·ª±a, S∆°n, Keo, Ph·ª• ki·ªán)

                material_description: Professional description of the material visible in the image
                - Type and characteristics
                - Surface finish
                - Quality indicators

                search_keywords:
                - Object 1: Specific material keywords (e.g., "g·ªó teak", "da b√≤ th·∫≠t", "v·∫£i linen cao c·∫•p")
                - Object 2: General material keywords (e.g., "g·ªó t·ª± nhi√™n", "da", "v·∫£i")

                color_tone: Material color

                material_properties: Special properties (waterproof, durable, premium, etc.)

                ƒê·ªäNH D·∫†NG OUTPUT
                Return JSON array: [ {{...}}, {{...}} ]
                No markdown, no explanation.
                Language: Vietnamese.

                V√ç D·ª§:
                Image: Wooden table with teak finish
                User: "t√¨m v·∫≠t li·ªáu g·ªó trong ·∫£nh"
                Output: [
                    {{
                        "material_group": "G·ªó",
                        "material_description": "G·ªó teak t·ª± nhi√™n, v√¢n g·ªó r√µ n√©t, b·ªÅ m·∫∑t ƒë√°nh b√≥ng l√°ng m·ªãn, m√†u n√¢u v√†ng ·∫•m √°p",
                        "search_keywords": "g·ªó teak t·ª± nhi√™n",
                        "color_tone": "N√¢u v√†ng",
                        "material_properties": "Cao c·∫•p, b·ªÅn, ch·ªëng m·ªëi m·ªçt"
                    }},
                    {{
                        "material_group": "G·ªó",
                        "material_description": "G·ªó t·ª± nhi√™n, v√¢n g·ªó ƒë·∫πp, b·ªÅ m·∫∑t ho√†n thi·ªán t·ªët",
                        "search_keywords": "g·ªó t·ª± nhi√™n",
                        "color_tone": "N√¢u",
                        "material_properties": "T·ª± nhi√™n, b·ªÅn"
                    }}
                ]

                B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH V·∫¨T LI·ªÜU TRONG H√åNH ·∫¢NH N√ÄY
            """
        else:
            # PRODUCT SEARCH PROMPT (original)
            prompt = f"""
                ROLE
                You are a Senior Interior Materials Analyst at AA Corporation with expertise in analyzing products based on both visual and textual information.

                TASK
                Analyze the provided image AND the user's description to extract comprehensive technical information for database search.

                USER'S DESCRIPTION & REQUIREMENTS:
                {description}

                CHI·∫æN L∆Ø·ª¢C D·ªÆ LI·ªÜU (DATA STRATEGY)
                Output ph·∫£i l√† m·ªôt m·∫£ng ch·ª©a ch√≠nh x√°c 2 ƒë·ªëi t∆∞·ª£ng (objects):

                Object 1 (∆Øu ti√™n): K·∫øt h·ª£p th√¥ng tin t·ª´ h√¨nh ·∫£nh V√Ä m√¥ t·∫£ c·ªßa user ƒë·ªÉ t·∫°o t·ª´ kh√≥a t√¨m ki·∫øm ch√≠nh x√°c nh·∫•t.
                - ∆Øu ti√™n c√°c y√™u c·∫ßu c·ª• th·ªÉ t·ª´ user (m√†u s·∫Øc, k√≠ch th∆∞·ªõc, ch·∫•t li·ªáu, phong c√°ch...)
                - K·∫øt h·ª£p v·ªõi ƒë·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t t·ª´ h√¨nh ·∫£nh

                Object 2 (D·ª± ph√≤ng): T√¨m ki·∫øm m·ªü r·ªông d·ª±a tr√™n danh m·ª•c chung.

                H∆Ø·ªöNG D·∫™N C√ÅC TR∆Ø·ªúNG (FIELDS)
                category: Danh m·ª•c s·∫£n ph·∫©m (Gh·∫ø, B√†n, Sofa, T·ªß, ƒê√®n, Gi∆∞·ªùng, K·ªá...)

                visual_description: M√¥ t·∫£ chuy√™n nghi·ªáp k·∫øt h·ª£p:
                - Nh·ªØng g√¨ nh√¨n th·∫•y t·ª´ h√¨nh ·∫£nh
                - Y√™u c·∫ßu c·ª• th·ªÉ t·ª´ m√¥ t·∫£ c·ªßa user
                - Phong c√°ch, ch·∫•t li·ªáu, m√†u s·∫Øc, k√≠ch th∆∞·ªõc...

                search_keywords:
                - Object 1: T·ª´ kh√≥a chi ti·∫øt k·∫øt h·ª£p y√™u c·∫ßu user + ƒë·∫∑c ƒëi·ªÉm h√¨nh ·∫£nh
                - Object 2: T·ª´ kh√≥a t·ªïng qu√°t h∆°n

                material_detected: V·∫≠t li·ªáu nh√¨n th·∫•y t·ª´ h√¨nh ·∫£nh ho·∫∑c ƒë∆∞·ª£c user ƒë·ªÅ c·∫≠p

                color_tone: M√†u s·∫Øc (t·ª´ h√¨nh ·∫£nh ho·∫∑c y√™u c·∫ßu c·ªßa user)

                user_requirements: T√≥m t·∫Øt c√°c y√™u c·∫ßu ƒë·∫∑c bi·ªát c·ªßa user (k√≠ch th∆∞·ªõc, gi√°, t√≠nh nƒÉng...)

                ƒê·ªäNH D·∫†NG OUTPUT
                Tr·∫£ v·ªÅ JSON array: [ {{...}}, {{...}} ]
                Kh√¥ng d√πng markdown, kh√¥ng gi·∫£i th√≠ch th√™m.
                Ng√¥n ng·ªØ: Ti·∫øng Vi·ªát.

                V√ç D·ª§:
                User description: "T√¥i c·∫ßn gh·∫ø vƒÉn ph√≤ng m√†u x√°m, c√≥ t·ª±a l∆∞ng cao, gi√° d∆∞·ªõi 3 tri·ªáu"
                Output: [
                    {{
                        "category": "Gh·∫ø",
                        "visual_description": "Gh·∫ø vƒÉn ph√≤ng c√¥ng th√°i h·ªçc l∆∞ng cao, khung nh·ª±a PP ƒëen k·∫øt h·ª£p l∆∞·ªõi tho√°ng kh√≠ m√†u x√°m. Tay v·ªãn nh·ª±a ch·ªØ T ƒëi·ªÅu ch·ªânh ƒë∆∞·ª£c. ƒê·ªám ng·ªìi b·ªçc v·∫£i m√†u x√°m x·ªëp √™m. Ch√¢n sao 5 c√°nh th√©p m·∫° c√≥ b√°nh xe, c·∫ßn n√¢ng h·∫° kh√≠ n√©n. Thi·∫øt k·∫ø theo y√™u c·∫ßu: m√†u x√°m, l∆∞ng cao, ph√π h·ª£p vƒÉn ph√≤ng.",
                        "search_keywords": "gh·∫ø vƒÉn ph√≤ng l∆∞ng cao x√°m",
                        "material_detected": "L∆∞·ªõi, Nh·ª±a PP, Th√©p m·∫°, V·∫£i",
                        "color_tone": "X√°m, ƒêen",
                        "user_requirements": "M√†u x√°m, t·ª±a l∆∞ng cao, gi√° < 3 tri·ªáu"
                    }},
                    {{
                        "category": "Gh·∫ø",
                        "visual_description": "Gh·∫ø vƒÉn ph√≤ng c√¥ng th√°i h·ªçc l∆∞ng cao, khung nh·ª±a PP ƒëen k·∫øt h·ª£p l∆∞·ªõi tho√°ng kh√≠ m√†u x√°m. Tay v·ªãn nh·ª±a ch·ªØ T ƒëi·ªÅu ch·ªânh ƒë∆∞·ª£c. ƒê·ªám ng·ªìi b·ªçc v·∫£i m√†u x√°m x·ªëp √™m. Ch√¢n sao 5 c√°nh th√©p m·∫° c√≥ b√°nh xe, c·∫ßn n√¢ng h·∫° kh√≠ n√©n.",
                        "search_keywords": "gh·∫ø vƒÉn ph√≤ng",
                        "material_detected": "L∆∞·ªõi, Nh·ª±a PP, Th√©p m·∫°, V·∫£i",
                        "color_tone": "X√°m, ƒêen",
                        "user_requirements": "M√†u x√°m, t·ª±a l∆∞ng cao, gi√° < 3 tri·ªáu"
                    }}
                ]

                B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH H√åNH ·∫¢NH N√ÄY
            """
        
        # Generate content with both image and prompt
        response = model.generate_content([prompt, img])
        
        if not response.text:
            return {
                "response": "‚ö†Ô∏è Kh√¥ng ph√¢n t√≠ch ƒë∆∞·ª£c ·∫£nh v√† m√¥ t·∫£. Vui l√≤ng th·ª≠ l·∫°i.",
                "products": [],
                "materials": []
            }
        
        # Parse AI response
        clean = response.text.strip()
        if "```json" in clean:
            clean = clean.split("```json")[1].split("```")[0].strip()
        elif "```" in clean:
            clean = clean.split("```")[1].split("```")[0].strip()
        try:
            ai_result = json.loads(clean)
        except json.JSONDecodeError as e:
            print(f"JSON Parse Error: {e}")
            return {
                "response": "‚ö†Ô∏è L·ªói ph√¢n t√≠ch d·ªØ li·ªáu. Vui l√≤ng th·ª≠ l·∫°i.",
                "products": [],
                "materials": [],
                "success": False,
            }
        
        print(f"INFO: AI Image+Text Analysis Result ({search_mode} mode): {ai_result}")
        
        # ========== BRANCH BASED ON SEARCH MODE ==========
        if search_mode == "material":
            # ===== MATERIAL SEARCH LOGIC =====
            from .embeddingapi import generate_embedding_qwen
            
            material_keywords = ai_result[0].get("search_keywords", "").strip()
            material_group = ai_result[0].get("material_group", "")
            material_description = ai_result[0].get("material_description", "")
            
            # Prepare search text
            if not material_keywords or len(material_keywords) > 50:
                search_text = material_group
            else:
                words = material_keywords.split()[:3]
                search_text = " ".join(words)
            
            print(f"INFO: Material search keywords: {search_text}")
            
            # Generate embedding for material search
            material_vector = generate_embedding_qwen(search_text)
            
            if not material_vector:
                return {
                    "response": "‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫°o vector t√¨m ki·∫øm. Vui l√≤ng th·ª≠ l·∫°i.",
                    "materials": [],
                    "success": False
                }
            
            # Search materials in database
            conn = get_db()
            cur = conn.cursor(cursor_factory=RealDictCursor)
            
            try:
                # Primary material search with vector similarity
                material_filter = ""
                filter_params = [material_vector]
                
                if material_group:
                    material_filter = "AND material_group ILIKE %s"
                    filter_params.append(f"%{material_group}%")
                
                sql = f"""
                    SELECT 
                        id_sap,
                        material_name,
                        material_group,
                        material_subgroup,
                        material_subprice,
                        unit,
                        image_url,
                        (name_embedding <=> %s::vector) as similarity
                    FROM {settings.MATERIALS_TABLE}
                    WHERE name_embedding IS NOT NULL
                    {material_filter}
                    ORDER BY similarity ASC
                    LIMIT 20
                """
                
                cur.execute(sql, filter_params)
                materials = cur.fetchall()
                conn.close()
                
                # Get latest prices for materials
                from .textfunc import get_latest_material_price
                materials_list = []
                for mat in materials:
                    mat_dict = dict(mat)
                    mat_dict['price'] = get_latest_material_price(mat['material_subprice'])
                    mat_dict['similarity_score'] = 1 - mat['similarity']  # Convert distance to similarity
                    materials_list.append(mat_dict)
                
                # Classify materials by confidence
                materials_main = [m for m in materials_list if m['similarity_score'] >= 0.75]
                materials_low = [m for m in materials_list if m['similarity_score'] < 0.75]
                
                print(f"INFO: Material search - Found {len(materials_main)} high confidence materials")
                
                # Save to chat history
                histories.save_chat_to_histories(
                    email="test@gmail.com",
                    session_id=session_id,
                    question=f"[IMAGE+TEXT MATERIAL] {description[:100]}...",
                    answer=f"Ph√¢n t√≠ch v·∫≠t li·ªáu: {material_description[:100]}... | T√¨m th·∫•y {len(materials_main)} v·∫≠t li·ªáu ph√π h·ª£p"
                )
                
                # Build response message
                if materials_main:
                    response_msg = f"üéâ **Ph√¢n t√≠ch v·∫≠t li·ªáu t·ª´ h√¨nh ·∫£nh:**\n\n"
                    response_msg += f"üîç **M√¥ t·∫£ v·∫≠t li·ªáu:** {material_description}\n\n"
                    response_msg += f"‚úÖ T√¥i t√¨m th·∫•y **{len(materials_main)} v·∫≠t li·ªáu ph√π h·ª£p** v·ªõi y√™u c·∫ßu c·ªßa b·∫°n!"
                else:
                    response_msg = f"üéâ **Ph√¢n t√≠ch v·∫≠t li·ªáu:**\n\n"
                    response_msg += f"üîç **M√¥ t·∫£:** {material_description}\n\n"
                    response_msg += f"‚ö†Ô∏è R·∫•t ti·∫øc, t√¥i ch∆∞a t√¨m th·∫•y v·∫≠t li·ªáu ho√†n to√†n ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n.\n\n"
                    response_msg += f"‚≠ê **Ghi ch√∫:** B·∫°n c√≥ th·ªÉ th·ª≠ m√¥ t·∫£ chi ti·∫øt h∆°n ho·∫∑c ƒëi·ªÅu ch·ªânh y√™u c·∫ßu c·ªßa b·∫°n."
                
                tmp = generate_suggested_prompts(
                    "search_product_not_found",
                    {"query": material_keywords}
                )
                suggested_prompts_mess = format_suggested_prompts(tmp)
                
                return {
                    "response": response_msg,
                    "materials": materials_main if materials_main else materials_list[:5],
                    "materials_low_confidence": materials_low[:5] if materials_low else [],
                    "ai_interpretation": material_description,
                    "search_method": "image_text_material_search",
                    "search_mode": "material",
                    "confidence_summary": {
                        "materials_main_count": len(materials_main),
                        "low_confidence_count": len(materials_low)
                    },
                    "success": True,
                    "suggested_prompts_mess": suggested_prompts_mess
                }
                
            except Exception as e:
                print(f"ERROR: Material search failed: {e}")
                import traceback
                traceback.print_exc()
                conn.close()
                return {
                    "response": f"‚ö†Ô∏è L·ªói t√¨m ki·∫øm v·∫≠t li·ªáu: {str(e)}",
                    "materials": [],
                    "success": False
                }
        
        else:
            # ===== PRODUCT SEARCH LOGIC (ORIGINAL) =====
            search_keywords = ai_result[0].get("search_keywords", "").strip()
            category = ai_result[0].get("category", "")
            user_requirements = ai_result[0].get("user_requirements", "")
            
            # Prepare search text
            if not search_keywords or len(search_keywords) > 50:
                search_text = category
                print(f"INFO: Using category as search term: {search_text}")
            else:
                words = search_keywords.split()[:4]  # Use up to 4 words for better matching
                search_text = " ".join(words)
                print(f"INFO: Using keywords: {search_text}")
            
            # Get secondary keywords if available
            secondary_keywords = ""
            secondary_category = ""
            if len(ai_result) > 1:
                secondary_keywords = ai_result[1].get("search_keywords", "").strip()
                secondary_category = ai_result[1].get("category", "")
            
            # Prepare search parameters
            params = {
                "category": category,
                "keywords_vector": search_text,
                "material_primary": ai_result[0].get("material_detected"),
                "main_keywords": search_keywords,
                "secondary_keywords": secondary_keywords,
                "secondary_category": secondary_category,
                "user_description": description  # Include original user description
            }
            
            print(f"INFO: Search params - Main: {search_keywords}, Secondary: {secondary_keywords}")
            print(f"INFO: User requirements: {user_requirements}")
            
            # Execute search
            search_result = search_products(params, session_id=session_id, disable_fallback=True)
            
            products = search_result.get("products", []) or []
            products_second = search_result.get("products_second", []) or []
            
            print(f"INFO: Search results - Main: {len(products)}, Secondary: {len(products_second)}")
            
            # Validate products against image and text description
            ai_interpretation = ai_result[0].get("visual_description", "").lower()
            description_lower = description.lower()
            
            for product in products:
                product_name = (product.get('product_name') or '').lower()
                category_prod = (product.get('category') or '').lower()
                
                # Check match with AI interpretation and user description
                name_match = any(word in ai_interpretation or word in description_lower 
                                for word in product_name.split() if len(word) > 2)
                category_match = category_prod in ai_interpretation or category_prod in description_lower
                
                if not name_match and not category_match:
                    current_score = product.get('base_score', 0.6)
                    penalty = 0.2
                    product['base_score'] = max(0, current_score - penalty)
                    product['mismatch'] = True
                    print(f"  ‚ö†Ô∏è Mismatch penalty for {product.get('headcode')}: {current_score:.3f} -> {product['base_score']:.3f}")
                else:
                    product['mismatch'] = False
            
            # Classify products by confidence score
            products_main = [p for p in products if p.get('final_score', 0) >= 0.75]
            products_second_main = [p for p in products_second if p.get('similarity', 0) >= 0.6 and p.get('final_score', 0) < 0.75] if products_second else []
            products_low_confidence = [p for p in products if p.get('similarity', 0) < 0.6]
            
            print(f"INFO: Final results - Main: {len(products_main)}, Secondary: {len(products_second_main)}, Low: {len(products_low_confidence)}")
            
            # Save to chat history
            histories.save_chat_to_histories(
                email="test@gmail.com",
                session_id=session_id,
                question=f"[IMAGE+TEXT PRODUCT] {description[:100]}...",
                answer=f"Ph√¢n t√≠ch: {ai_result[0].get('visual_description', '')[:100]}... | T√¨m th·∫•y {len(products_main)} s·∫£n ph·∫©m ph√π h·ª£p v·ªõi y√™u c·∫ßu, {len(products_second_main)} s·∫£n ph·∫©m ph·ª•"
            )
            
            # Build response message
            if products_main or products_second_main:
                response_msg = f" üéâ **Ph√¢n t√≠ch h√¨nh ·∫£nh v√† y√™u c·∫ßu c·ªßa b·∫°n:**\n\n"
                response_msg += f" üîç **M√¥ t·∫£ s·∫£n ph·∫©m:** {ai_result[0].get('visual_description', 'N/A')}\n\n"
                if user_requirements:
                    response_msg += f" ‚ú® **Y√™u c·∫ßu c·ªßa b·∫°n:** {user_requirements}\n\n"
                
                if products_main:
                    response_msg += f" ‚úÖ T√¥i t√¨m th·∫•y **{len(products_main)} s·∫£n ph·∫©m ph√π h·ª£p** v·ªõi y√™u c·∫ßu c·ªßa b·∫°n"
                if products_main and products_second_main:
                    response_msg += f"Nh·ªØng s·∫£n ph·∫©m tr√™n c√≥ ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n kh√¥ng?. N·∫øu kh√¥ng h√£y ƒë·ªÉ t√¥i t√¨m ki·∫øm th√™m cho b·∫°n"
                
            elif not products_main and products_second_main:
                response_msg = f" üéâ **Ph√¢n t√≠ch h√¨nh ·∫£nh v√† y√™u c·∫ßu c·ªßa b·∫°n:**\n\n"
                response_msg += f" üîç **M√¥ t·∫£ s·∫£n ph·∫©m:** {ai_result[0].get('visual_description', 'N/A')}\n\n"
                if user_requirements:
                    response_msg += f" ‚ú® **Y√™u c·∫ßu c·ªßa b·∫°n:** {user_requirements}\n\n"
                response_msg += f"‚ö†Ô∏è R·∫•t ti·∫øc, t√¥i ch∆∞a t√¨m th·∫•y s·∫£n ph·∫©m ho√†n to√†n ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n trong c∆° s·ªü d·ªØ li·ªáu.\n\n"
            else:
                response_msg = f" üéâ **Ph√¢n t√≠ch h√¨nh ·∫£nh v√† y√™u c·∫ßu:**\n\n"
                response_msg += f" üîç **M√¥ t·∫£:** {ai_result[0].get('visual_description', 'N/A')}\n\n"
                if user_requirements:
                    response_msg += f"‚ú® **Y√™u c·∫ßu:** {user_requirements}\n\n"
                response_msg += f"‚ö†Ô∏è R·∫•t ti·∫øc, t√¥i ch∆∞a t√¨m th·∫•y s·∫£n ph·∫©m ho√†n to√†n ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n.\n\n"
                response_msg += f" ‚≠ê **Ghi ch√∫:** B·∫°n c√≥ th·ªÉ th·ª≠ m√¥ t·∫£ chi ti·∫øt h∆°n ho·∫∑c ƒëi·ªÅu ch·ªânh y√™u c·∫ßu c·ªßa b·∫°n."

            tmp = generate_suggested_prompts(
                            "search_product_not_found",
                            {"query": user_requirements}
                        )
            suggested_prompts_mess = format_suggested_prompts(tmp)
            
            return {
                "response": response_msg,
                "products": products_main if products_main else None,
                "products_second": products_second_main if products_second_main else None,
                "products_low_confidence": products_low_confidence[:5] if products_low_confidence else [],
                "ai_interpretation": ai_result[0].get("visual_description", ""),
                "user_requirements": user_requirements,
                "search_method": "image_text_combined_search",
                "search_mode": "product",
                "confidence_summary": {
                    "products_main_count": len(products_main),
                    "products_second_count": len(products_second_main),
                    "low_confidence_count": len(products_low_confidence)
                },
                "success": True,
                "suggested_prompts_mess": suggested_prompts_mess
            }
    
    except Exception as e:
        print(f"ERROR: Image+Text search error: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            "response": f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω: {str(e)}. Vui l√≤ng th·ª≠ l·∫°i.",
            "products": [],
            "success": False,
        }
    
    finally:
        # Clean up temporary file
        if os.path.exists(file_path):
            try:
                os.remove(file_path)
            except:
                pass
