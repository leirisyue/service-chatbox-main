import json
import time
from io import BytesIO
from typing import Dict, List

import google.generativeai as genai
import numpy as np
import psycopg2
from openpyxl import Workbook
from openpyxl.styles import Alignment, Font, PatternFill
from psycopg2.extras import RealDictCursor

from config import settings

from .embeddingapi import generate_embedding_qwen


def get_db():
    return psycopg2.connect(**settings.DB_CONFIG)

def format_suggested_prompts(prompts: list[str]) -> str:
    if not prompts:
        return ""
    return "\n".join([f"‚Ä¢ {p}" for p in prompts])

def extract_product_keywords(query: str) -> list:
    """Tr√≠ch xu·∫•t t·ª´ kh√≥a quan tr·ªçng, bao g·ªìm c·ª•m t·ª´"""
    materials = ["g·ªó teak", "g·ªó s·ªìi", "g·ªó walnut", "ƒë√° marble", "ƒë√° granite", 
                    "da th·∫≠t", "da b√≤", "v·∫£i linen", "kim lo·∫°i", "teak", "oak", 
                    "walnut", "marble", "granite", "leather"]
    
    contexts = ["nh√† b·∫øp", "ph√≤ng kh√°ch", "ph√≤ng ng·ªß", "vƒÉn ph√≤ng",
                "kitchen", "living room", "dining", "coffee", "bar",
                "b√†n ƒÉn", "b√†n tr√†", "b√†n l√†m vi·ªác"]
    
    shapes = ["tr√≤n", "vu√¥ng", "ch·ªØ nh·∫≠t", "oval", "l-shape", 
                "round", "square", "rectangular"]
    
    table_types = ["b√†n l√†m vi·ªác", "b√†n ƒÉn", "b√†n tr√†", "b√†n coffee", 
                    "b√†n h·ªçc", "b√†n m√°y t√≠nh", "working table", "desk", 
                    "dining table", "coffee table", "study table"]
    
    chair_types = ["gh·∫ø ƒÉn", "gh·∫ø bar", "gh·∫ø sofa", "gh·∫ø vƒÉn ph√≤ng",
                    "dining chair", "bar chair", "office chair"]
    
    types = ["b√†n", "gh·∫ø", "t·ªß", "gi∆∞·ªùng", "sofa", "k·ªá", "ƒë√®n",
                "table", "chair", "cabinet", "bed", "shelf", "lamp"]
    
    query_lower = query.lower()
    keywords = []
    
    for word_list in [table_types, chair_types, materials, contexts, shapes]:
        for word in word_list:
            if word in query_lower:
                keywords.append(word)
    
    for word in types:
        if word in query_lower:
            if not any(word in kw for kw in keywords):
                keywords.append(word)
    
    keywords = list(set(keywords))
    if keywords:
        print(f"INFO: Keywords => {keywords}")
    return keywords

def auto_classify_product(product_name: str, id_sap: str = "") -> Dict:
    """T·ª± ƒë·ªông ph√¢n lo·∫°i s·∫£n ph·∫©m b·∫±ng AI"""
    model = genai.GenerativeModel("gemini-2.5-flash")
    
    prompt = f"""
                B·∫°n l√† chuy√™n gia ph√¢n lo·∫°i s·∫£n ph·∫©m n·ªôi th·∫•t cao c·∫•p.
                INPUT:
                - T√™n s·∫£n ph·∫©m: "{product_name}"
                - M√£ SAP: "{id_sap}"
                NHI·ªÜM V·ª§: Ph√¢n t√≠ch v√† ph√¢n lo·∫°i s·∫£n ph·∫©m theo 3 ti√™u ch√≠:
                1. **category** (Danh m·ª•c ch√≠nh):
                - B√†n (Table)
                - Gh·∫ø (Chair) 
                - Sofa
                - T·ªß (Cabinet)
                - Gi∆∞·ªùng (Bed)
                - ƒê√®n (Lamp)
                - K·ªá (Shelf)
                - B√†n l√†m vi·ªác (Desk)
                - Kh√°c (Other)
                2. **sub_category** (Danh m·ª•c ph·ª• - c·ª• th·ªÉ h∆°n):
                VD: "B√†n ƒÉn", "B√†n coffee", "Gh·∫ø bar", "Gh·∫ø ƒÉn", "Sofa g√≥c", "T·ªß qu·∫ßn √°o", "ƒê√®n b√†n", "ƒê√®n tr·∫ßn"...
                3. **material_primary** (V·∫≠t li·ªáu ch√≠nh):
                - G·ªó (Wood)
                - Da (Leather)
                - V·∫£i (Fabric)
                - Kim lo·∫°i (Metal)
                - ƒê√° (Stone)
                - K√≠nh (Glass)
                - Nh·ª±a (Plastic)
                - M√¢y tre (Rattan)
                - H·ªón h·ª£p (Mixed)
                OUTPUT JSON ONLY (no markdown, no backticks):
                {{
                "category": "...",
                "sub_category": "...",
                "material_primary": "..."
                }}
        """
    
    response_text = call_gemini_with_retry(model, prompt)
    
    if not response_text:
        return {
            "category": "Ch∆∞a ph√¢n lo·∫°i",
            "sub_category": "Ch∆∞a ph√¢n lo·∫°i", 
            "material_primary": "Ch∆∞a x√°c ƒë·ªãnh"
        }
    
    try:
        clean = response_text.strip()
        if "```json" in clean:
            clean = clean.split("```json")[1].split("```")[0].strip()
        elif "```" in clean:
            clean = clean.split("```")[1].split("```")[0].strip()
        
        result = json.loads(clean)
        return result
    except:
        return {
            "category": "Ch∆∞a ph√¢n lo·∫°i",
            "sub_category": "Ch∆∞a ph√¢n lo·∫°i",
            "material_primary": "Ch∆∞a x√°c ƒë·ªãnh"
        }

def auto_classify_material(material_name: str, id_sap: str = "") -> Dict:
    """T·ª± ƒë·ªông ph√¢n lo·∫°i v·∫≠t li·ªáu b·∫±ng AI"""
    model = genai.GenerativeModel("gemini-2.5-flash")
    
    prompt = f"""
                Ph√¢n lo·∫°i nguy√™n v·∫≠t li·ªáu n·ªôi th·∫•t:
                T√™n: "{material_name}"
                M√£: "{id_sap}"
                X√°c ƒë·ªãnh:
                1. **material_group**: G·ªó, Da, V·∫£i, ƒê√°, Kim lo·∫°i, K√≠nh, Nh·ª±a, S∆°n, Keo, Ph·ª• ki·ªán, Kh√°c
                2. **material_subgroup**: Nh√≥m con c·ª• th·ªÉ (VD: "G·ªó t·ª± nhi√™n", "Da th·∫≠t", "V·∫£i cao c·∫•p"...)
                OUTPUT JSON ONLY:
                {{
                    "material_group": "...",
                    "material_subgroup": "..."
                }}
        """
    
    response_text = call_gemini_with_retry(model, prompt)
    
    if not response_text:
        return {
            "material_group": "Ch∆∞a ph√¢n lo·∫°i",
            "material_subgroup": "Ch∆∞a ph√¢n lo·∫°i"
        }
    
    try:
        clean = response_text.strip()
        if "```json" in clean:
            clean = clean.split("```json")[1].split("```")[0].strip()
        elif "```" in clean:
            clean = clean.split("```")[1].split("```")[0].strip()
        
        result = json.loads(clean)
        return result
    except:
        return {
            "material_group": "Ch∆∞a ph√¢n lo·∫°i",
            "material_subgroup": "Ch∆∞a ph√¢n lo·∫°i"
        }

def search_materials_for_product(product_query: str, params: Dict):
    """
    üîç T√åM V·∫¨T LI·ªÜU ƒê·ªÇ L√ÄM S·∫¢N PH·∫®M C·ª§ TH·ªÇ
    V√≠ d·ª•: "V·∫≠t li·ªáu l√†m b√†n tr√≤n", "Nguy√™n li·ªáu gh·∫ø sofa"
    
    Logic:
    1. T√¨m products ph√π h·ª£p v·ªõi query
    2. JOIN product_materials ƒë·ªÉ l·∫•y materials ƒë∆∞·ª£c d√πng
    3. Aggregate + rank theo t·∫ßn su·∫•t
    """
    conn = get_db()
    cur = conn.cursor(cursor_factory=RealDictCursor)
    
    print(f"INFO: Cross-table search: Materials for '{product_query}'")
    
    # B∆∞·ªõc 1: T√¨m products ph√π h·ª£p
    product_vector = generate_embedding_qwen(product_query)
    
    if not product_vector:
        conn.close()
        return {"materials": [], "search_method": "failed"}
    
    try:
        cur.execute("""
            SELECT 
                headcode,
                product_name,
                category,
                (description_embedding <=> %s::vector) as distance
            FROM products_qwen
            WHERE description_embedding IS NOT NULL
            ORDER BY distance ASC
            LIMIT 10
        """, [product_vector])
        
        matched_products = cur.fetchall()
        
        if not matched_products:
            conn.close()
            return {"materials": [], "search_method": "no_products_found"}
        
        product_headcodes = [p['headcode'] for p in matched_products]
        product_names = [p['product_name'] for p in matched_products]
        
        print(f"SUCCESS: Found {len(product_headcodes)} matching products: {product_names[:3]}")
        
        # B∆∞·ªõc 2: L·∫•y materials ƒë∆∞·ª£c d√πng trong products n√†y
        material_filter = ""
        filter_params = []
        
        if params.get("material_group"):
            material_filter = "AND m.material_group ILIKE %s"
            filter_params.append(f"%{params['material_group']}%")
        
        sql = f"""
            SELECT 
                m.id_sap,
                m.material_name,
                m.material_group,
                m.material_subgroup,
                m.material_subprice,
                m.unit,
                m.image_url,
                COUNT(DISTINCT pm.product_headcode) as usage_count,
                SUM(pm.quantity) as total_quantity,
                array_agg(DISTINCT p.product_name) as used_in_products
            FROM {settings.MATERIALS_TABLE} m
            INNER JOIN product_materials pm ON m.id_sap = pm.material_id_sap
            INNER JOIN products_qwen p ON pm.product_headcode = p.headcode
            WHERE p.headcode = ANY(%s)
            {material_filter}
            GROUP BY m.id_sap, m.material_name, m.material_group, 
                    m.material_subgroup, m.material_subprice, m.unit, m.image_url
            ORDER BY usage_count DESC, m.material_name ASC
            LIMIT 15
        """
        
        cur.execute(sql, [product_headcodes] + filter_params)
        results = cur.fetchall()
        
        conn.close()
        
        if not results:
            return {
                "materials": [],
                "search_method": "cross_table_no_materials",
                "matched_products": product_names
            }
        
        materials_with_context = []
        for mat in results:
            mat_dict = dict(mat)
            mat_dict['price'] = get_latest_material_price(mat['material_subprice'])
            mat_dict['used_in_products_list'] = mat['used_in_products'][:5]  # Top 5
            materials_with_context.append(mat_dict)
        
        print(f"SUCCESS: Found {len(materials_with_context)} materials used in these products")
        
        return {
            "materials": materials_with_context,
            "search_method": "cross_table_product_to_material",
            "matched_products": product_names[:5],
            "explanation": f"V·∫≠t li·ªáu th∆∞·ªùng d√πng cho: {', '.join(product_names[:3])}"
        }
        
    except Exception as e:
        print(f"ERROR: Cross-table materials search failed: {e}")
        conn.close()
        return {"materials": [], "search_method": "cross_table_error"}

def get_adaptive_threshold(query: str) -> float:
    """
    T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh threshold:
    - Query d√†i, c·ª• th·ªÉ ‚Üí threshold th·∫•p (0.75)
    - Query ng·∫Øn, chung chung ‚Üí threshold cao (0.90)
    """
    words = query.split()
    
    if len(words) >= 8:
        return 0.75  # Query d√†i ‚Üí d·ªÖ d√£i h∆°n
    elif len(words) >= 5:
        return 0.82
    else:
        return 0.90  

def format_search_results(results):
    """Format results th√†nh c·∫•u tr√∫c chu·∫©n"""
    products = []
    for row in results:
        products.append({
            "headcode": row["headcode"],
            "product_name": row["product_name"],
            "category": row.get("category"),
            "sub_category": row.get("sub_category"),
            "material_primary": row.get("material_primary"),
            "project": row.get("project"),
            "project_id": row.get("project_id"),
            "similarity": round(1 - row["distance"], 3) if "distance" in row else None
        })
    return products

def call_gemini_with_retry(model, prompt, max_retries=3, timeout=20):
    """G·ªçi Gemini v·ªõi retry logic v√† timeout"""
    import signal
    
    def timeout_handler(signum, frame):
        raise TimeoutError("Gemini API timeout")
    
    for attempt in range(max_retries):
        try:
            # Set timeout for this attempt (only on Unix systems)
            if hasattr(signal, 'SIGALRM'):
                signal.signal(signal.SIGALRM, timeout_handler)
                signal.alarm(timeout)
            
            response = model.generate_content(prompt, request_options={"timeout": timeout})
            
            # Cancel alarm
            if hasattr(signal, 'SIGALRM'):
                signal.alarm(0)
            
            if response.text:
                return response.text
        except TimeoutError:
            print(f"WARNING: Gemini timeout after {timeout}s on attempt {attempt + 1}")
            if attempt == max_retries - 1:
                return None
            continue
        except Exception as e:
            # Cancel alarm on error
            if hasattr(signal, 'SIGALRM'):
                signal.alarm(0)
            
            if "429" in str(e) or "quota" in str(e).lower():
                wait_time = 5 * (2 ** attempt)
                print(f"INFO: Quota exceeded. ƒê·ª£i {wait_time}s...")
                time.sleep(wait_time)
                continue
            print(f"ERROR Gemini: {e}")
            return None
    return None

def calculate_product_total_cost(headcode: str) -> float:
    """T√≠nh t·ªïng chi ph√≠ (total_cost) cho m·ªôt s·∫£n ph·∫©m"""
    conn = get_db()
    cur = conn.cursor(cursor_factory=RealDictCursor)
    
    sql = """
        SELECT 
            m.material_subprice,
            pm.quantity
        FROM product_materials pm
        INNER JOIN materials m ON pm.material_id_sap = m.id_sap
        WHERE pm.product_headcode = %s
    """
    try:
        cur.execute(sql, (headcode,))
        materials = cur.fetchall()
    except Exception as e:
        print(f"ERROR: Query error in calculate_product_total_cost for {headcode}: {e}")
        conn.close()
        return 0.0
    conn.close()
    if not materials:
        return 0.0
    
    material_cost = 0
    for mat in materials:
        quantity = float(mat['quantity']) if mat['quantity'] else 0.0
        latest_price = get_latest_material_price(mat['material_subprice'])
        material_cost += quantity * latest_price  # S·ª≠a l·ªói: c·ªông d·ªìn material_cost

    labor_cost = material_cost * 0.20
    overhead_cost = material_cost * 0.15
    profit_margin = material_cost * 0.25
    
    total_cost = material_cost + labor_cost + overhead_cost + profit_margin
    return total_cost

def search_products_hybrid(params: Dict):
    """HYBRID: Vector + Keyword v·ªõi t·ª´ CH√çNH b·∫Øt bu·ªôc kh·ªõp, t·ª´ PH·ª§ t√¨m g·∫ßn gi·ªëng"""
    import signal
    
    def timeout_handler(signum, frame):
        raise TimeoutError("Search timeout")
    
    # Set timeout cho to√†n b·ªô search operation (20 gi√¢y)
    if hasattr(signal, 'SIGALRM'):
        signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(20)
    
    conn = get_db()
    cur = conn.cursor(cursor_factory=RealDictCursor)
    
    # 1. Chu·∫©n b·ªã query
    if params.get("keywords_vector"):
        base = params["keywords_vector"]
    else:
        parts = [params.get("category", ""), params.get("sub_category", ""), 
                params.get("material_primary", "")]
        base = " ".join([p for p in parts if p]) or "n·ªôi th·∫•t"
    
    # ‚úÖ X·ª¨ L√ù ƒê·∫∂C BI·ªÜT: T√¨m "danh s√°ch s·∫£n ph·∫©m" - l·∫•y 1 s·∫£n ph·∫©m m·ªói lo·∫°i
    query_lower = base.lower()
    if "danh s√°ch" in query_lower or "product list" in query_lower or "product catalog" in query_lower:
        print(f"üîç Special query detected: Product list - returning one product per category")
        try:
            sql = """
                SELECT DISTINCT ON (category) 
                    headcode, product_name, category, sub_category, 
                    material_primary, project, project_id
                FROM products_qwen
                WHERE category IS NOT NULL
                    AND category != ''
                ORDER BY category, headcode
                LIMIT 10
            """
            cur.execute(sql)
            products = cur.fetchall()
            
            if products:
                result = []
                for p in products:
                    result.append({
                        "headcode": p["headcode"],
                        "product_name": p["product_name"],
                        "category": p.get("category"),
                        "sub_category": p.get("sub_category"),
                        "material_primary": p.get("material_primary"),
                        "project": p.get("project"),
                        "project_id": p.get("project_id"),
                        "similarity": 0.9,
                        "final_score": 0.9
                    })
                
                conn.close()
                if hasattr(signal, 'SIGALRM'):
                    signal.alarm(0)
                
                print(f"SUCCESS: Found {len(result)} products (one per category)")
                return {
                    "products": result,
                    "search_method": "product_list_by_category",
                    "expanded_query": base
                }
        except Exception as e:
            print(f"ERROR: Error in product list query: {e}")
            # Fall through to normal search if error
    
    # print(f"\nüîç Query: {base}")
    
    # 2. AI Expansion v·ªõi timeout ng·∫Øn h∆°n
    expanded = expand_search_query(base, params)
    
    # 3. Extract keywords
    keywords = extract_product_keywords(expanded)
    
    # 4. T√°ch t·ª´ trong query g·ªëc
    original_words = [w.strip().lower() for w in base.split() if len(w.strip()) > 1]
    
    # 5. X√ÅC ƒê·ªäNH T·ª™ CH√çNH (lo·∫°i s·∫£n ph·∫©m) - PH·∫¢I KH·ªöP CH√çNH X√ÅC
    main_product_types = ["b√†n", "gh·∫ø", "t·ªß", "gi∆∞·ªùng", "sofa", "k·ªá", "ƒë√®n", "g∆∞∆°ng",
                          "table", "chair", "cabinet", "bed", "shelf", "lamp", "mirror"]
    
    main_word = None
    secondary_words = []
    
    for word in original_words:
        if word in main_product_types:
            main_word = word
            break
    
    # N·∫øu kh√¥ng t√¨m th·∫•y t·ª´ ch√≠nh trong danh s√°ch, l·∫•y t·ª´ ƒë·∫ßu ti√™n l√†m t·ª´ ch√≠nh
    if not main_word and original_words:
        main_word = original_words[0]
    
    # C√°c t·ª´ c√≤n l·∫°i l√† t·ª´ ph·ª•
    secondary_words = [w for w in original_words if w != main_word]
    
    print(f"üîç Main word (REQUIRED): '{main_word}' | Secondary: {secondary_words}")
    
    # 6. Vector
    vector = generate_embedding_qwen(expanded)
    if not vector:
        conn.close()
        if hasattr(signal, 'SIGALRM'):
            signal.alarm(0)
        return {"products": [], "search_method": "failed", "error": "no_vector"}
    
    # 7. B∆Ø·ªöC 1: T√¨m trong DATABASE v·ªõi T·ª™ CH√çNH (keyword search)
    try:
        if not main_word:
            print("‚ö†Ô∏è No main word detected, returning empty")
            conn.close()
            if hasattr(signal, 'SIGALRM'):
                signal.alarm(0)
            return {"products": [], "search_method": "no_main_word"}
        
        # B∆Ø·ªöC 1: Query database v·ªõi t·ª´ CH√çNH - CH·ªà T√åM TRONG PRODUCT_NAME
        print(f"STEP 1: Query DB with main word: '{main_word}'")
        
        sql_step1 = """
            SELECT headcode, product_name, category, sub_category, 
                   material_primary, project, project_id, description_embedding
            FROM products_qwen
            WHERE description_embedding IS NOT NULL
                AND product_name ILIKE %s
            LIMIT 100
        """
        
        cur.execute(sql_step1, [f"%{main_word}%"])
        candidates = cur.fetchall()
        
        if not candidates:
            print(f"ERROR: No products found with main word '{main_word}' in product_name")
            conn.close()
            if hasattr(signal, 'SIGALRM'):
                signal.alarm(0)
            return {
                "products": [],
                "search_method": "no_candidates_with_main_word",
                "main_word": main_word
            }
    
    except TimeoutError:
        print(f"‚è±Ô∏è Search timeout exceeded - returning empty result")
        try:
            conn.close()
        except:
            pass
        if hasattr(signal, 'SIGALRM'):
            signal.alarm(0)
        return {
            "products": [],
            "search_method": "timeout",
            "error": "search_timeout"
        }
    except Exception as e:
        print(f"ERROR: Search error: {e}")
        try:
            conn.close()
        except:
            pass
        if hasattr(signal, 'SIGALRM'):
            signal.alarm(0)
        return {
            "products": [],
            "search_method": "error",
            "error": str(e)
        }
    finally:
        # Lu√¥n cancel alarm
        if hasattr(signal, 'SIGALRM'):
            try:
                signal.alarm(0)
            except:
                pass
    
    # Continue v·ªõi logic c≈© n·∫øu c√≥ candidates
    try:
        
        print(f"SUCCESS: Found {len(candidates)} candidates with '{main_word}'")
        
        # B∆Ø·ªöC 2: T√≠nh vector similarity cho t·ª´ PH·ª§
        # TƒÉng ng∆∞·ª°ng ƒë·ªÉ lo·∫°i b·ªè s·∫£n ph·∫©m kh√¥ng li√™n quan
        SIMILARITY_THRESHOLD = 0.35  
        MIN_SECONDARY_MATCH_RATIO = 0.5  # T·ªëi thi·ªÉu 50% t·ª´ ph·ª• ph·∫£i kh·ªõp
        
        # T·∫°o vector cho query PH·ª§ (kh√¥ng bao g·ªìm t·ª´ ch√≠nh)
        if secondary_words:
            secondary_query = " ".join(secondary_words)
            secondary_vector = generate_embedding_qwen(secondary_query)
        else:
            # N·∫øu kh√¥ng c√≥ t·ª´ ph·ª•, d√πng to√†n b·ªô query
            secondary_vector = vector
            # Kh√¥ng c·∫ßn filter n·∫øu ch·ªâ c√≥ 1 t·ª´
            MIN_SECONDARY_MATCH_RATIO = 0
        
        # T√≠nh similarity cho t·ª´ng candidate
        scored_products = []
        for candidate in candidates:
            product_name = candidate["product_name"].lower()
            
            # T√≠nh vector similarity
            if candidate["description_embedding"] and secondary_vector:
                # Convert embedding t·ª´ string ho·∫∑c list sang numpy array
                candidate_emb = candidate["description_embedding"]
                if isinstance(candidate_emb, str):
                    candidate_emb = json.loads(candidate_emb)
                
                candidate_np = np.array(candidate_emb)
                query_np = np.array(secondary_vector)
                
                # Cosine similarity
                dot_product = np.dot(candidate_np, query_np)
                norm_a = np.linalg.norm(candidate_np)
                norm_b = np.linalg.norm(query_np)
                similarity = dot_product / (norm_a * norm_b) if (norm_a * norm_b) > 0 else 0
                similarity = float(similarity)
            else:
                similarity = 0.0
            
            # ƒê·∫øm s·ªë t·ª´ ph·ª• kh·ªõp ch√≠nh x√°c
            secondary_match_count = sum(1 for word in secondary_words if word in product_name)
            secondary_match_ratio = secondary_match_count / len(secondary_words) if secondary_words else 1.0
            
            # T√≠nh final score - ∆ØU TI√äN exact match H∆†N
            final_score = (secondary_match_ratio * 0.6) + (similarity * 0.4)
            
            # Th√™m v√†o list scored_products
            scored_products.append({
                "headcode": candidate["headcode"],
                "product_name": candidate["product_name"],
                "category": candidate.get("category"),
                "sub_category": candidate.get("sub_category"),
                "material_primary": candidate.get("material_primary"),
                "project": candidate.get("project"),
                "project_id": candidate.get("project_id"),
                "similarity": round(similarity, 3),
                "secondary_match_count": secondary_match_count,
                "secondary_match_ratio": round(secondary_match_ratio, 2),
                "final_score": round(final_score, 3)
            })
        
        # L·ªçc theo ƒêI·ªÄU KI·ªÜN CH·∫∂T:
        # 1. Similarity >= ng∆∞·ª°ng
        # 2. N·∫øu c√≥ t·ª´ ph·ª•: ph·∫£i kh·ªõp t·ªëi thi·ªÉu 50% t·ª´ ph·ª• HO·∫∂C similarity r·∫•t cao (>0.6)
        filtered_products = []
        for p in scored_products:
            # ƒêi·ªÅu ki·ªán 1: Similarity ƒë·∫°t ng∆∞·ª°ng c∆° b·∫£n
            if p["similarity"] < SIMILARITY_THRESHOLD:
                continue
            
            # ƒêi·ªÅu ki·ªán 2: N·∫øu c√≥ t·ª´ ph·ª•, ph·∫£i kh·ªõp ƒë·ªß t·ª´ ho·∫∑c similarity r·∫•t cao
            if secondary_words:
                if p["secondary_match_ratio"] >= MIN_SECONDARY_MATCH_RATIO or p["similarity"] >= 0.6:
                    filtered_products.append(p)
            else:
                # Kh√¥ng c√≥ t·ª´ ph·ª• th√¨ ch·ªâ c·∫ßn similarity
                filtered_products.append(p)
        
        # Sort theo final_score
        filtered_products.sort(key=lambda x: x["final_score"], reverse=True)
        
        # Gi·ªõi h·∫°n 10 s·∫£n ph·∫©m
        filtered_products = filtered_products[:10]
        
        if filtered_products:
            print(f"SUCCESS: Final: {len(filtered_products)} products (main: '{main_word}', secondary match, similarity >= {SIMILARITY_THRESHOLD})")
            for i, p in enumerate(filtered_products[:3], 1):
                print(f"  {i}. {p['product_name']} (score: {p['final_score']}, sim: {p['similarity']})")
            
            conn.close()
            return {
                "products": filtered_products,
                "search_method": "two_step_main_word_vector",
                "expanded_query": expanded,
                "main_word": main_word,
                "secondary_words": secondary_words
            }
        else:
            print(f"ERROR: No products meet similarity threshold (>= {SIMILARITY_THRESHOLD})")
            conn.close()
            return {
                "products": [],
                "search_method": "no_match_after_filtering",
                "main_word": main_word
            }
            
    except Exception as e:
        print(f"ERROR: {e}")
        import traceback
        traceback.print_exc()
    
    conn.close()
    return {"products": [], "search_method": "hybrid_failed"}

def expand_search_query(user_query: str, params: Dict) -> str:
    """AI m·ªü r·ªông query ng·∫Øn th√†nh m√¥ t·∫£ chi ti·∫øt v·ªõi t·ª´ kh√≥a ch√≠nh x√°c"""
    model = genai.GenerativeModel("gemini-2.5-flash")
    
    prompt = f"""
            Ng∆∞·ªùi d√πng t√¨m: "{user_query}"

            T·∫°o m√¥ t·∫£ t√¨m ki·∫øm t·ªëi ∆∞u (2-3 c√¢u ng·∫Øn), GI·ªÆ NGUY√äN T·ª™ KH√ìA CH√çNH t·ª´ c√¢u g·ªëc:
            1. LO·∫†I S·∫¢N PH·∫®M CH√çNH X√ÅC (b√†n/gh·∫ø/t·ªß...) - PH·∫¢I kh·ªõp v·ªõi t·ª´ kh√≥a g·ªëc
            2. V·∫¨T LI·ªÜU C·ª§ TH·ªÇ (g·ªó teak/ƒë√° marble/da b√≤...)
            3. V·ªä TR√ç/C√îNG D·ª§NG (nh√† b·∫øp/ph√≤ng kh√°ch/dining/coffee...)

            QUAN TR·ªåNG: 
            - N·∫æU ng∆∞·ªùi d√πng t√¨m "b√†n l√†m vi·ªác" th√¨ PH·∫¢I nh·∫•n m·∫°nh "b√†n l√†m vi·ªác", "desk", "working table"
            - KH√îNG m·ªü r·ªông sang lo·∫°i s·∫£n ph·∫©m kh√°c (v√≠ d·ª•: t√¨m "b√†n" th√¨ kh√¥ng nh·∫Øc ƒë·∫øn "gh·∫ø")
            - Ch·ªâ b·ªï sung t·ª´ ƒë·ªìng nghƒ©a v√† chi ti·∫øt v·ªÅ lo·∫°i s·∫£n ph·∫©m C·ª§ TH·ªÇ ƒëang t√¨m

            VD: 
            - "b√†n l√†m vi·ªác" -> "B√†n l√†m vi·ªác desk working table vƒÉn ph√≤ng. Office desk b√†n h·ªçc b√†n m√°y t√≠nh."
            - "b√†n g·ªó teak" -> "B√†n l√†m t·ª´ g·ªó teak t·ª± nhi√™n. Dining table ho·∫∑c coffee table ch·∫•t li·ªáu teak wood cao c·∫•p."

            Output (ch·ªâ m√¥ t·∫£, t·∫≠p trung v√†o t·ª´ kh√≥a ch√≠nh):
        """
    
    try:
        response = call_gemini_with_retry(model, prompt, max_retries=2)
        if response:
            # ƒê·∫£m b·∫£o t·ª´ kh√≥a g·ªëc c√≥ trong expanded query
            expanded = response.strip()
            if user_query.lower() not in expanded.lower():
                expanded = f"{user_query} {expanded}"
            print(f"Expanded: '{user_query}' -> '{expanded[:100]}...'")
            return expanded
    except:
        pass
    return user_query

def get_latest_material_price(material_subprice_json: str) -> float:
    """L·∫•y gi√° m·ªõi nh·∫•t t·ª´ JSON l·ªãch s·ª≠ gi√°"""
    if not material_subprice_json:
        return 0.0
    
    try:
        price_history = json.loads(material_subprice_json)
        if not price_history or not isinstance(price_history, list):
            return 0.0
        
        sorted_prices = sorted(
            price_history, 
            key=lambda x: x.get('date', '1900-01-01'), 
            reverse=True
        )
        
        return float(sorted_prices[0].get('price', 0))
    except:
        return 0.0

def search_products_keyword_only(params: Dict):
    """TIER 3: Fallback keyword search"""
    conn = get_db()
    cur = conn.cursor(cursor_factory=RealDictCursor)
    
    conditions = []
    values = []
    
    if params.get("category"):
        cat = params['category']
        conditions.append("(category ILIKE %s OR sub_category ILIKE %s OR product_name ILIKE %s)")
        values.extend([f"%{cat}%", f"%{cat}%", f"%{cat}%"])
    
    if params.get("material_primary"):
        mat = params['material_primary']
        conditions.append("(material_primary ILIKE %s OR product_name ILIKE %s)")
        values.extend([f"%{mat}%", f"%{mat}%"])
    
    if conditions:
        where_clause = " OR ".join(conditions)
        sql = f"SELECT * FROM products_qwen WHERE {where_clause} LIMIT 12"
    else:
        sql = "SELECT * FROM products_qwen ORDER BY RANDOM() LIMIT 10"
        values = []
    
    try:
        cur.execute(sql, values)
        results = cur.fetchall()
        conn.close()
        
        if not results:
            return {
                "response": "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p.",
                "products": []
            }
        
        print(f"SUCCESS: TIER 3 => Found {len(results)} products")
        products = []
        for r in results:
            product = dict(r)
            product["total_cost"] = calculate_product_total_cost(product["headcode"])
            products.append(product)
        
        return {
            "products": products,
            "search_method": "keyword"
        }
    except Exception as e:
        conn.close()
        print(f"ERROR: TIER 3 failed: {e}")
        return {
            "response": "L·ªói t√¨m ki·∫øm.",
            "products": []
        }

def calculate_personalized_score(
    candidate_vector: list, 
    session_id: str
) -> float:
    """
    üéØ V5.7 - Tr·∫£ v·ªÅ ƒëi·ªÉm Personalization RI√äNG (0.0 ‚Üí 1.0)
    KH√îNG tr·∫£ v·ªÅ final_score, ƒë·ªÉ search_products t·ªïng h·ª£p sau
    
    Returns:
        float: Personal affinity score (0.0 = kh√¥ng kh·ªõp, 1.0 = r·∫•t kh·ªõp)
    """
    try:
        conn = get_db()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # L·∫•y 10 interactions g·∫ßn nh·∫•t
        cur.execute("""
            SELECT product_vector, weight
            FROM user_preferences
            WHERE session_id = %s
            ORDER BY created_at DESC
            LIMIT 10
        """, (session_id,))
        
        history = cur.fetchall()
        conn.close()
        
        if not history:
            return 0.5  # Neutral score khi ch∆∞a c√≥ history
        
        # Convert candidate sang numpy
        if isinstance(candidate_vector, str):
            candidate_np = np.array(json.loads(candidate_vector), dtype=np.float32)
        else:
            candidate_np = np.array(candidate_vector, dtype=np.float32)
        
        positive_scores = []
        negative_scores = []
        
        for record in history:
            try:
                vec_data = record['product_vector']
                
                if vec_data is None:
                    continue
                    
                # Parse vector
                if isinstance(vec_data, str):
                    hist_vector = np.array(json.loads(vec_data), dtype=np.float32)
                elif isinstance(vec_data, list):
                    hist_vector = np.array(vec_data, dtype=np.float32)
                else:
                    continue
                
                # Check dimension match
                if len(hist_vector) != len(candidate_np):
                    continue
                
                # Cosine Similarity
                norm_product = np.linalg.norm(candidate_np) * np.linalg.norm(hist_vector)
                if norm_product < 1e-8:
                    continue
                    
                similarity = np.dot(candidate_np, hist_vector) / norm_product
                
                # Ph√¢n lo·∫°i theo weight
                if record['weight'] > 0:
                    positive_scores.append(similarity)
                else:
                    negative_scores.append(similarity)
                    
            except Exception:
                continue
        
        # Fallback n·∫øu kh√¥ng c√≥ scores h·ª£p l·ªá
        if not positive_scores and not negative_scores:
            return 0.5
        
        # T√≠nh ƒëi·ªÉm affinity thu·∫ßn t√∫y
        positive_affinity = np.mean(positive_scores) if positive_scores else 0.0
        negative_penalty = np.mean(negative_scores) if negative_scores else 0.0
        
        # Formula: Positive boost - Negative penalty
        personal_score = positive_affinity - (negative_penalty * 0.5)
        
        # Clip v·ªÅ [0, 1]
        personal_score = float(np.clip(personal_score, 0.0, 1.0))
        
        return personal_score
        
    except Exception as e:
        print(f"WARNING: Personalization error: {e}")
        return 0.5

def generate_consolidated_report(product_headcodes: List[str]) -> BytesIO:
    """
    T·∫°o b√°o c√°o Excel t·ªïng h·ª£p ƒë·ªãnh m·ª©c v·∫≠t t∆∞ cho nhi·ªÅu s·∫£n ph·∫©m
    
    Args:
        product_headcodes: Danh s√°ch m√£ s·∫£n ph·∫©m
    
    Returns:
        BytesIO: File Excel buffer
    """
    conn = get_db()
    cur = conn.cursor(cursor_factory=RealDictCursor)
    
    # 1. L·∫§Y TH√îNG TIN S·∫¢N PH·∫®M
    cur.execute("""
        SELECT headcode, product_name, category, sub_category, project
        FROM products_qwen 
        WHERE headcode = ANY(%s)
        ORDER BY product_name
    """, (product_headcodes,))
    
    selected_products = cur.fetchall()
    
    if not selected_products:
        raise ValueError("Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†o")
    
    # 2. L·∫§Y ƒê·ªäNH M·ª®C CHI TI·∫æT (Flatten View)
    cur.execute("""
        SELECT 
            p.headcode,
            p.product_name,
            m.id_sap,
            m.material_name,
            m.material_group,
            m.material_subgroup,
            m.unit as material_unit,
            pm.quantity,
            pm.unit as pm_unit,
            m.material_subprice
        FROM product_materials pm
        INNER JOIN products_qwen p ON pm.product_headcode = p.headcode
        INNER JOIN materials m ON pm.material_id_sap = m.id_sap
        WHERE p.headcode = ANY(%s)
        ORDER BY p.product_name, m.material_name
    """, (product_headcodes,))
    
    detail_records = cur.fetchall()
    conn.close()
    
    if not detail_records:
        raise ValueError("C√°c s·∫£n ph·∫©m n√†y ch∆∞a c√≥ ƒë·ªãnh m·ª©c v·∫≠t t∆∞")
    
    # 3. AGGREGATION - G·ªòP V·∫¨T T∆Ø
    material_summary = {}
    
    for record in detail_records:
        id_sap = record['id_sap']
        quantity = float(record['quantity']) if record['quantity'] else 0.0
        
        # Parse gi√° m·ªõi nh·∫•t
        latest_price = get_latest_material_price(record['material_subprice'])
        
        if id_sap not in material_summary:
            material_summary[id_sap] = {
                'id_sap': id_sap,
                'material_name': record['material_name'],
                'material_group': record['material_group'],
                'material_subgroup': record['material_subgroup'],
                'unit': record['material_unit'],
                'total_quantity': 0.0,
                'unit_price': latest_price,
                'total_cost': 0.0,
                'used_in_products': []
            }
        
        # C·ªông d·ªìn s·ªë l∆∞·ª£ng
        material_summary[id_sap]['total_quantity'] += quantity
        material_summary[id_sap]['used_in_products'].append(
            f"{record['product_name']} ({quantity} {record['pm_unit']})"
        )
    
    # T√≠nh th√†nh ti·ªÅn
    for mat_id, mat_data in material_summary.items():
        mat_data['total_cost'] = mat_data['total_quantity'] * mat_data['unit_price']
    
    # 4. T·∫†O EXCEL FILE
    wb = Workbook()
    
    # --- SHEET 1: OVERVIEW (Danh s√°ch SP ƒë√£ ch·ªçn) ---
    ws_overview = wb.active
    ws_overview.title = "Overview"
    
    # Header styling
    header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
    header_font = Font(bold=True, color="FFFFFF", size=12)
    
    # Headers
    overview_headers = ["STT", "M√£ SP", "T√™n S·∫£n Ph·∫©m", "Danh M·ª•c", "D·ª± √Ån"]
    for col_idx, header in enumerate(overview_headers, 1):
        cell = ws_overview.cell(row=1, column=col_idx, value=header)
        cell.fill = header_fill
        cell.font = header_font
        cell.alignment = Alignment(horizontal="center", vertical="center")
    
    # Data rows
    for idx, prod in enumerate(selected_products, 1):
        ws_overview.append([
            idx,
            prod['headcode'],
            prod['product_name'],
            f"{prod.get('category', '')} - {prod.get('sub_category', '')}",
            prod.get('project', '')
        ])
    
    # Auto-adjust column width
    for col in ws_overview.columns:
        max_length = max(len(str(cell.value or "")) for cell in col)
        ws_overview.column_dimensions[col[0].column_letter].width = min(max_length + 2, 50)
    
    # --- SHEET 2: MATERIAL SUMMARY (T·ªïng h·ª£p v·∫≠t t∆∞) ---
    ws_summary = wb.create_sheet("Material Summary")
    
    summary_headers = [
        "STT", "M√£ SAP", "T√™n V·∫≠t Li·ªáu", "Nh√≥m", 
        "Nh√≥m Con", "ƒê∆°n V·ªã", "T·ªïng SL", "ƒê∆°n Gi√° (VNƒê)", "Th√†nh Ti·ªÅn (VNƒê)"
    ]
    
    for col_idx, header in enumerate(summary_headers, 1):
        cell = ws_summary.cell(row=1, column=col_idx, value=header)
        cell.fill = header_fill
        cell.font = header_font
        cell.alignment = Alignment(horizontal="center", vertical="center")
    
    # Sort by total_cost DESC
    sorted_materials = sorted(
        material_summary.values(), 
        key=lambda x: x['total_cost'], 
        reverse=True
    )
    
    total_cost_all = 0.0
    
    for idx, mat in enumerate(sorted_materials, 1):
        ws_summary.append([
            idx,
            mat['id_sap'],
            mat['material_name'],
            mat['material_group'],
            mat['material_subgroup'],
            mat['unit'],
            round(mat['total_quantity'], 2),
            round(mat['unit_price'], 2),
            round(mat['total_cost'], 2)
        ])
        total_cost_all += mat['total_cost']
    
    # T·ªîNG C·ªòNG ROW
    summary_row = ws_summary.max_row + 1
    ws_summary.cell(row=summary_row, column=7, value="T·ªîNG C·ªòNG:").font = Font(bold=True)
    ws_summary.cell(row=summary_row, column=9, value=round(total_cost_all, 2)).font = Font(bold=True, color="FF0000")
    
    for col in ws_summary.columns:
        max_length = max(len(str(cell.value or "")) for cell in col)
        ws_summary.column_dimensions[col[0].column_letter].width = min(max_length + 2, 50)
    
    # --- SHEET 3: DETAILS (Chi ti·∫øt theo SP) ---
    ws_details = wb.create_sheet("Details")
    
    detail_headers = [
        "M√£ SP", "T√™n SP", "M√£ SAP", "T√™n V·∫≠t Li·ªáu", 
        "Nh√≥m VL", "S·ªë L∆∞·ª£ng", "ƒê∆°n V·ªã", "ƒê∆°n Gi√°", "Th√†nh Ti·ªÅn"
    ]
    
    for col_idx, header in enumerate(detail_headers, 1):
        cell = ws_details.cell(row=1, column=col_idx, value=header)
        cell.fill = header_fill
        cell.font = header_font
        cell.alignment = Alignment(horizontal="center", vertical="center")
    
    for record in detail_records:
        quantity = float(record['quantity']) if record['quantity'] else 0.0
        unit_price = get_latest_material_price(record['material_subprice'])
        total_cost = quantity * unit_price
        
        ws_details.append([
            record['headcode'],
            record['product_name'],
            record['id_sap'],
            record['material_name'],
            record['material_group'],
            round(quantity, 2),
            record['pm_unit'],
            round(unit_price, 2),
            round(total_cost, 2)
        ])
    
    for col in ws_details.columns:
        max_length = max(len(str(cell.value or "")) for cell in col)
        ws_details.column_dimensions[col[0].column_letter].width = min(max_length + 2, 50)
    
    # 5. SAVE TO BUFFER
    buffer = BytesIO()
    wb.save(buffer)
    buffer.seek(0)
    
    return buffer
