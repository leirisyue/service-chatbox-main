
import json
import os
import time
import uuid
from typing import Dict, List

import google.generativeai as genai
import psycopg2
from fastapi import (APIRouter, File, Form, UploadFile)
from historiesapi import histories
from PIL import Image
from psycopg2.extras import RealDictCursor

from .textfunc import call_gemini_with_retry,format_suggested_prompts
from .textapi_qwen import generate_suggested_prompts, search_products
from config import settings

def get_db():
    return psycopg2.connect(**settings.DB_CONFIG)

router = APIRouter()
# ================================================================================================
# FUNCTION DEFINITIONS
# ================================================================================================
    
def batch_classify_materials(materials_batch: List[Dict]) -> List[Dict]:
    if not materials_batch:
        return []
    
    # [FIX] Switch to gemini-1.5-flash model for better stability and to avoid Rate Limit errors
    model = genai.GenerativeModel("gemini-2.5-flash")
    
    materials_text = ""
    for i, mat in enumerate(materials_batch, 1):
        materials_text += f"{i}. ID: {mat['id_sap']}, TÃªn: {mat['name']}\n"
    
    prompt = f"""
                PhÃ¢n loáº¡i {len(materials_batch)} nguyÃªn váº­t liá»‡u ná»™i tháº¥t:
                {materials_text}
                XÃ¡c Ä‘á»‹nh:
                1. material_group: Gá»—, Da, Váº£i, ÄÃ¡, Kim loáº¡i, KÃ­nh, Nhá»±a, SÆ¡n, Keo, Phá»¥ kiá»‡n, KhÃ¡c
                2. material_subgroup: NhÃ³m con cá»¥ thá»ƒ (VD: "Gá»— tá»± nhiÃªn", "Da tháº­t", "Váº£i cao cáº¥p")
                OUTPUT JSON ARRAY ONLY:
                [
                    {{"id_sap": "M001", "material_group": "...", "material_subgroup": "..."}},
                    {{"id_sap": "M002", "material_group": "...", "material_subgroup": "..."}}
                ]
            """
    
    # Call Gemini with retry
    response_text = call_gemini_with_retry(model, prompt, max_retries=3)
    
    # Create default results (Fallback) to return if AI fails
    default_results = [{
        'id_sap': m['id_sap'],
        'material_group': 'Not classified',
        'material_subgroup': 'Not classified'
    } for m in materials_batch]

    if not response_text:
        return default_results
    
    try:
        clean = response_text.strip()
        # Clean markdown JSON
        if "```json" in clean:
            clean = clean.split("```json")[1].split("```")[0].strip()
        elif "```" in clean:
            clean = clean.split("```")[1].split("```")[0].strip()
        
        results = json.loads(clean)
        
        # Check if number of results matches input
        if len(results) != len(materials_batch):
            print(f"WARNING: Batch materials mismatch: expected {len(materials_batch)}, got {len(results)}")
            return default_results
        
        return results
        
    except Exception as e:
        print(f"ERROR: Batch materials classification error: {e}")
        return default_results

def batch_classify_products(products_batch: List[Dict]) -> List[Dict]:
    if not products_batch:
        return []
    
    # [FIX] Switch to stable model to avoid Rate Limit errors from Experimental version
    model = genai.GenerativeModel("gemini-2.5-flash")
    
    # Create product list in prompt
    products_text = ""
    for i, prod in enumerate(products_batch, 1):
        products_text += f"{i}. ID: {prod['id_sap']}, Name: {prod['name']}\n"
    
    prompt = f"""
            Báº¡n lÃ  chuyÃªn gia phÃ¢n loáº¡i sáº£n pháº©m ná»™i tháº¥t cao cáº¥p.
            PhÃ¢n loáº¡i {len(products_batch)} sáº£n pháº©m sau:
            {products_text}
            Má»—i sáº£n pháº©m cáº§n phÃ¢n loáº¡i theo:
            1. category: BÃ n, Gháº¿, Sofa, Tá»§, GiÆ°á»ng, ÄÃ¨n, Ká»‡, BÃ n lÃ m viá»‡c, KhÃ¡c
            2. sub_category: Danh má»¥c phá»¥ cá»¥ thá»ƒ (VD: "BÃ n Äƒn", "Gháº¿ bar", "Sofa gÃ³c"...)
            3. material_primary: Gá»—, Da, Váº£i, Kim loáº¡i, ÄÃ¡, KÃ­nh, Nhá»±a, MÃ¢y tre, Há»—n há»£p
            OUTPUT JSON ARRAY ONLY (no markdown, no backticks):
            [
                {{"id_sap": "SP001", "category": "...", "sub_category": "...", "material_primary": "..."}},
                {{"id_sap": "SP002", "category": "...", "sub_category": "...", "material_primary": "..."}}
            ]
    """
    
    # Call AI with retry logic
    response_text = call_gemini_with_retry(model, prompt, max_retries=3)
    
    # Default fallback if AI completely fails
    default_results = [{
        'id_sap': p['id_sap'],
        'category': 'ChÆ°a phÃ¢n loáº¡i',
        'sub_category': 'ChÆ°a phÃ¢n loáº¡i',
        'material_primary': 'ChÆ°a xÃ¡c Ä‘á»‹nh'
    } for p in products_batch]

    if not response_text:
        return default_results
    
    try:
        clean = response_text.strip()
        # Handle case when Gemini returns markdown code block
        if "```json" in clean:
            clean = clean.split("```json")[1].split("```")[0].strip()
        elif "```" in clean:
            clean = clean.split("```")[1].split("```")[0].strip()
        
        results = json.loads(clean)
        
        # Ensure result count matches input
        if len(results) != len(products_batch):
            print(f"WARNING: Batch size mismatch: expected {len(products_batch)}, got {len(results)}")
            return default_results
        
        return results
        
    except Exception as e:
        print(f"ERROR: Batch classification parse error: {e}")
        return default_results

# ================================================================================================
# API ENDPOINTS
# ================================================================================================
@router.post("/search-image", tags=["Classifyapi"])
async def search_by_image(
    file: UploadFile = File(...),
    session_id: str = Form(default=str(uuid.uuid4()))
):
    file_path = f"./media/temp_{uuid.uuid4()}.jpg"
    try:
        # Read file content
        contents = await file.read()
        
        # Save to temporary file
        with open(file_path, "wb") as buffer:
            buffer.write(contents)
        
        # Open image using PIL
        img = Image.open(file_path)
        model = genai.GenerativeModel("gemini-2.5-flash")
        
        prompt = """
            ROLE
            You are a Senior Interior Materials Analyst at AA Corporation. You have deep knowledge of materials, construction, and interior design styles.

            TASK
            Analyze the provided image and extract technical information into a standard JSON Array format for input into the database search system.

            CHIáº¾N LÆ¯á»¢C Dá»® LIá»†U (DATA STRATEGY)
            Output pháº£i lÃ  má»™t máº£ng chá»©a chÃ­nh xÃ¡c 2 Ä‘á»‘i tÆ°á»£ng (objects) nháº±m phá»¥c vá»¥ cÆ¡ cháº¿ tÃ¬m kiáº¿m Ä‘a táº§ng:

            Object 1 (Æ¯u tiÃªn): TÃ¬m kiáº¿m chÃ­nh xÃ¡c (Exact Match). Tá»« khÃ³a pháº£i mÃ´ táº£ cá»¥ thá»ƒ Ä‘áº·c tÃ­nh ná»•i báº­t nháº¥t cá»§a sáº£n pháº©m, bao gá»“m hÃ¬nh thÃ¡i vÃ  cÃ´ng dá»¥ng.

            Object 2 (Dá»± phÃ²ng): TÃ¬m kiáº¿m má»Ÿ rá»™ng (Broad Match). Tá»« khÃ³a lÃ  danh má»¥c chung hoáº·c tá»« Ä‘á»“ng nghÄ©a Ä‘á»ƒ Ä‘áº£m báº£o káº¿t quáº£ tÃ¬m kiáº¿m khÃ´ng bá»‹ rá»—ng náº¿u tÃ¬m chÃ­nh xÃ¡c tháº¥t báº¡i.

            HÆ¯á»šNG DáºªN CÃC TRÆ¯á»œNG (FIELDS)
            category: Chá»‰ chá»n 1 danh má»¥c chÃ­nh xÃ¡c nháº¥t (VD: Gháº¿, BÃ n, Sofa, Tá»§, ÄÃ¨n...).

            visual_description: Viáº¿t Ä‘oáº¡n vÄƒn mÃ´ táº£ chuyÃªn nghiá»‡p (catalogue). Táº­p trung: cáº¥u trÃºc khung, cháº¥t liá»‡u bá» máº·t, tÃ­nh nÄƒng vÃ  cáº£m giÃ¡c sá»­ dá»¥ng. (Ná»™i dung nÃ y giá»‘ng nhau á»Ÿ cáº£ 2 object).

            search_keywords:

            Táº¡i Object 1: TrÃ­ch xuáº¥t tá»« khÃ³a "ngÃ¡ch" cá»¥ thá»ƒ, mÃ´ táº£ chi tiáº¿t (VD: "gháº¿ xoay lÆ°á»›i", "sofa da bÃ²", "bÃ n Äƒn máº·t Ä‘Ã¡", "gháº¿ vÄƒn phÃ²ng cÃ´ng thÃ¡i há»c",...).

            Táº¡i Object 2: TrÃ­ch xuáº¥t tá»« khÃ³a "gá»‘c" phá»• biáº¿n (VD: "gháº¿ vÄƒn phÃ²ng", "sofa phÃ²ng khÃ¡ch", "bÃ n Äƒn",..).

            material_detected: Liá»‡t kÃª váº­t liá»‡u nhÃ¬n tháº¥y, ngÄƒn cÃ¡ch báº±ng dáº¥u pháº©y. Æ¯u tiÃªn tá»« chuyÃªn ngÃ nh (Nhá»±a PP, ThÃ©p máº¡ chrome, Váº£i ná»‰...).

            color_tone: MÃ u sáº¯c chá»§ Ä‘áº¡o (Tá»‘i Ä‘a 2 mÃ u).

            Äá»ŠNH Dáº NG OUTPUT (CONSTRAINTS)
            Báº¯t buá»™c tráº£ vá» Ä‘á»‹nh dáº¡ng máº£ng JSON: [ {...}, {...} ].

            KhÃ´ng bao bá»c bá»Ÿi markdown (json ... ).

            KhÃ´ng thÃªm lá»i dáº«n hay giáº£i thÃ­ch.

            NgÃ´n ngá»¯: Tiáº¿ng Viá»‡t.

            VÃ Dá»¤ MáºªU (ONE-SHOT EXAMPLE)
            Input: [HÃ¬nh áº£nh má»™t chiáº¿c gháº¿ vÄƒn phÃ²ng lÆ°á»›i Ä‘en chÃ¢n xoay] Output: [ { "category": "Gháº¿", "visual_description": "Gháº¿ xoay vÄƒn phÃ²ng lÆ°ng trung, thiáº¿t káº¿ khung nhá»±a Ä‘Ãºc nguyÃªn khá»‘i káº¿t há»£p lÆ°ng lÆ°á»›i thoÃ¡ng khÃ­. Tay vá»‹n nhá»±a cá»‘ Ä‘á»‹nh dáº¡ng vÃ²m. Äá»‡m ngá»“i bá»c váº£i lÆ°á»›i xá»‘p Ãªm Ã¡i. ChÃ¢n gháº¿ sao 5 cÃ¡nh báº±ng thÃ©p máº¡ chrome sÃ¡ng bÃ³ng, cÃ³ bÃ¡nh xe di chuyá»ƒn vÃ  cáº§n gáº¡t Ä‘iá»u chá»‰nh Ä‘á»™ cao.", "search_keywords": "gháº¿ xoay lÆ°á»›i", "material_detected": "LÆ°á»›i, Nhá»±a PP, ThÃ©p máº¡ chrome, Váº£i, MÃºt", "color_tone": "Äen, Báº¡c" }, { "category": "Gháº¿", "visual_description": "Gháº¿ xoay vÄƒn phÃ²ng lÆ°ng trung, thiáº¿t káº¿ khung nhá»±a Ä‘Ãºc nguyÃªn khá»‘i káº¿t há»£p lÆ°ng lÆ°á»›i thoÃ¡ng khÃ­. Tay vá»‹n nhá»±a cá»‘ Ä‘á»‹nh dáº¡ng vÃ²m. Äá»‡m ngá»“i bá»c váº£i lÆ°á»›i xá»‘p Ãªm Ã¡i. ChÃ¢n gháº¿ sao 5 cÃ¡nh báº±ng thÃ©p máº¡ chrome sÃ¡ng bÃ³ng, cÃ³ bÃ¡nh xe di chuyá»ƒn vÃ  cáº§n gáº¡t Ä‘iá»u chá»‰nh Ä‘á»™ cao.", "search_keywords": "gháº¿ vÄƒn phÃ²ng", "material_detected": "LÆ°á»›i, Nhá»±a PP, ThÃ©p máº¡ chrome, Váº£i, MÃºt", "color_tone": "Äen, Báº¡c" } ]

            Báº®T Äáº¦U PHÃ‚N TÃCH HÃŒNH áº¢NH NÃ€Y
        """
        
        response = model.generate_content([prompt, img])
        
        # print("response Image analysis response:", response)
        
        if not response.text:
            return {
                "response": "âš ï¸ KhÃ´ng phÃ¢n tÃ­ch Ä‘Æ°á»£c áº£nh. Vui lÃ²ng thá»­ áº£nh khÃ¡c.",
                "products": []
            }
        
        clean = response.text.strip()
        
        if "```json" in clean:
            
            clean = clean.split("```json")[1].split("```")[0].strip()
        elif "```" in clean:
            clean = clean.split("```")[1].split("```")[0].strip()
        
        try:
            ai_result = json.loads(clean)
        except json.JSONDecodeError as e:
            print(f"JSON Parse Error: {e}")
            ai_result = {
                "visual_description": clean[:200],
                "search_keywords": "",
                "category": "Ná»™i tháº¥t"
            }
        
        print(f"INFO: AI Image Analysis Result: {ai_result}")
        # Get search_keywords and shorten if too long
        search_keywords = ai_result[0].get("search_keywords", "").strip()
        category = ai_result[0].get("category", "")
        
        # If search_keywords too long (>50 chars) or empty, use category
        if not search_keywords or len(search_keywords) > 50:
            search_text = category  # Only use simplest category
            print(f"INFO: Using category as search term: {search_text}")
        else:
            # Get max first 3 words of search_keywords
            words = search_keywords.split()[:3]
            search_text = " ".join(words)
            print(f"INFO: Using simplified keywords: {search_text}")
        
        # Get secondary keywords from ai_result[1] if available (for better matching)
        secondary_keywords = ""
        secondary_category = ""
        secondary_material = ""
        
        if len(ai_result) > 1:
            secondary_keywords = ai_result[1].get("search_keywords", "").strip()
            secondary_category = ai_result[1].get("category", "")
            secondary_material = ai_result[1].get("material_detected", "")
            print(f"INFO: Using secondary keywords from AI: {secondary_keywords}")
        
        # ========== PARALLEL SEARCH WITH BOTH MAIN & SECONDARY KEYWORDS ==========
        params = {
            "category": category,
            "keywords_vector": search_text,  # EXTREMELY simple keywords
            "material_primary": ai_result[0].get("material_detected"),
            "main_keywords": ai_result[0].get("search_keywords"),
            "secondary_keywords": secondary_keywords,
            "secondary_category": secondary_category,
            "secondary_material": secondary_material,
        }
        
        print(f"INFO: Parallel search - Main: {ai_result[0].get('search_keywords')}, Secondary: {secondary_keywords}")
        
        # Disable automatic fallback in search_products, we handle dual search here
        search_result = search_products(params, session_id=session_id, disable_fallback=True)
        
        products = search_result.get("products", [])
        products_second = search_result.get("products_second", [])
        
        # Handle case when search_products returns None or empty
        if products is None:
            products = []
        if products_second is None:
            products_second = []
        
        print(f"INFO: Parallel search results - Products: {len(products)}, Products second: {len(products_second)}")
        
        # ========== IMAGE MATCHING VALIDATION ==========
        # Products already have base_score from parallel search, just apply image matching validation
        ai_interpretation = ai_result[0].get("visual_description", "").lower()
        
        for product in products:
            product_name = (product.get('product_name') or '').lower()
            category_prod = (product.get('category') or '').lower()
            
            # Check if name or category is in ai_interpretation
            name_match = any(word in ai_interpretation for word in product_name.split() if len(word) > 2)
            category_match = category_prod in ai_interpretation
            
            # If no match â†’ deduct base_score
            if not name_match and not category_match:
                current_score = product.get('base_score', 0.6)
                penalty = 0.25  # Deduct 0.25 points
                product['base_score'] = max(0, current_score - penalty)
                product['image_mismatch'] = True
                product['penalty_applied'] = penalty
                print(f"  âš ï¸ Image mismatch penalty for {product.get('headcode')}: {current_score:.3f} -> {product['base_score']:.3f}")
            else:
                product['image_mismatch'] = False
        
        # # Apply same validation for products_second if they exist
        # if products_second and len(ai_result) > 1:
        #     ai_interpretation_second = ai_result[1].get("visual_description", "").lower()
            
        #     for product in products_second:
        #         product_name = (product.get('product_name') or '').lower()
        #         category_prod = (product.get('category') or '').lower()
                
        #         name_match = any(word in ai_interpretation_second for word in product_name.split() if len(word) > 2)
        #         category_match = category_prod in ai_interpretation_second
                
        #         if not name_match and not category_match:
        #             current_score = product.get('base_score', 0.5)
        #             penalty = 0.25
        #             product['base_score'] = max(0, current_score - penalty)
        #             product['image_mismatch'] = True
        #             product['penalty_applied'] = penalty
        #             print(f"  âš ï¸ Image mismatch penalty (2nd) for {product.get('headcode')}: {current_score:.3f} -> {product['base_score']:.3f}")
        #         else:
        #             product['image_mismatch'] = False
        
        print(f"\nINFO: Image search completed. Total Products: found: {products:}\n")
        print(f"\nINFO: Image search completed. Total Products second: found: {products_second:}\n")
        # Classify products by base_score
        products_main = [p for p in products if p.get('final_score', 0) >= 0.75]
        products_low_confidence = [p for p in products if p.get('similarity', 0) < 0.6]
        products_second_main = [p for p in products_second if p.get('similarity', 0) >= 0.6 and p.get('final_score', 0) < 0.75] if products_second else []
        
        print(f"INFO: Image search - Main products: {len(products_main)}, Products second: {len(products_second_main)}, Low confidence: {len(products_low_confidence)}")
        
        histories.save_chat_to_histories(
            email="test@gmail.com",
            session_id=session_id,
            question="[IMAGE_UPLOAD]",
            answer=f"PhÃ¢n tÃ­ch áº£nh: {ai_result[0].get('visual_description', 'N/A')[:100]}... | TÃ¬m tháº¥y {len(products_main)} sáº£n pháº©m theo yÃªu cáº§u cá»§a báº¡n, {len(products_second_main)} sáº£n pháº©m phá»¥"
        )
        response_msg = ""
        # Build response message based on results
        if products_main or products_second_main:
            response_msg = f"ðŸ“‹ **PhÃ¢n tÃ­ch áº£nh:** TÃ´i nháº­n tháº¥y Ä‘Ã¢y lÃ  **{ai_result[0].get('visual_description', 'sáº£n pháº©m')}**.\n\n"
            if products_main:
                response_msg += f"âœ… Dá»±a trÃªn hÃ¬nh áº£nh báº¡n Ä‘Ã£ táº£i lÃªn, tÃ´i cÃ³ **{len(products_main)} sáº£n pháº©m theo yÃªu cáº§u cá»§a báº¡n** gá»£i Ã½ cho báº¡n"
            # if products_second_main:
            #     response_msg += f"{', vÃ  ' if products_main else 'âœ… TÃ´i cÃ³ '}**{len(products_second_main)} sáº£n pháº©m tÆ°Æ¡ng tá»±** vá»›i yÃªu cáº§u trÃªn cá»§a báº¡n! Báº¡n cÃ³ thá»ƒ tham kháº£o"
            # response_msg += ":"
        if not products_main and products_second_main:
            response_msg = f"ðŸ“‹ **PhÃ¢n tÃ­ch áº£nh:** TÃ´i nháº­n tháº¥y Ä‘Ã¢y lÃ  **{ai_result[0].get('visual_description', 'sáº£n pháº©m ná»™i tháº¥t')}**.\n\n"
            response_msg += f"âš ï¸ Ráº¥t tiáº¿c, tÃ´i chÆ°a tÃ¬m tháº¥y sáº£n pháº©m hoÃ n toÃ n phÃ¹ há»£p vá»›i yÃªu cáº§u cá»§a báº¡n trong cÆ¡ sá»Ÿ dá»¯ liá»‡u.\n\n" 
            # response_msg += f"âœ… Tuy nhiÃªn, tÃ´i cÃ³ **{len(products_second_main)} sáº£n pháº©m tÆ°Æ¡ng tá»±** vá»›i yÃªu cáº§u cá»§a báº¡n! Báº¡n cÃ³ thá»ƒ tham kháº£o:"
        else:
            response_msg = f"ðŸ“‹ **PhÃ¢n tÃ­ch áº£nh:** TÃ´i nháº­n tháº¥y Ä‘Ã¢y lÃ  **{ai_result[0].get('visual_description', 'sáº£n pháº©m ná»™i tháº¥t')}**.\n\n"
            response_msg += f"ðŸ’”  Tháº­t xin lá»—i tÃ´i khÃ´ng tÃ¬m tháº¥y sáº£n pháº©m phÃ¹ há»£p vá»›i yÃªu cáº§u cá»§a báº¡n trong cÆ¡ sá»Ÿ dá»¯ liá»‡u.\n"
            response_msg = f"ðŸ“‹ **PhÃ¢n tÃ­ch áº£nh:** TÃ´i nháº­n tháº¥y Ä‘Ã¢y lÃ  **{ai_result[0].get('visual_description', 'sáº£n pháº©m ná»™i tháº¥t')}**.\n\n" \
                            f"ðŸ’”  Tháº­t xin lá»—i, ráº¥t tiáº¿c tÃ´i khÃ´ng tÃ¬m tháº¥y sáº£n pháº©m phÃ¹ há»£p vá»›i yÃªu cáº§u cá»§a báº¡n.\n\n" \
                            f"â­ **Ghi chÃº**: Báº¡n cÃ³ thá»ƒ mÃ´ táº£ chi tiáº¿t hÆ¡n. Hoáº·c báº¡n cÃ³ thá»ƒ tÃ¬m sáº£n pháº©m khÃ¡c. TÃ´i sáº½ gá»£i Ã½ cho báº¡n danh sÃ¡ch sáº£n pháº©m"

        tmp = generate_suggested_prompts(
                        "search_product_not_found",
                        {"query": "TÃ¬m sáº£n pháº©m trong áº£nh"}
                    )
        suggested_prompts_mess = format_suggested_prompts(tmp)
        return {
            "response": response_msg,
            "products": products_main if products_main else None,
            "products_second": products_second_main if products_second_main else None,
            "productLowConfidence": products_low_confidence[:5] if products_low_confidence else [],
            "ai_interpretation": ai_result[0].get("visual_description", ""),
            "search_method": "image_vector_dual_search",
            "confidence_summary": {
                "products_main_count": len(products_main),
                "products_second_count": len(products_second_main),
                "low_confidence": len(products_low_confidence)
            },
            "success": True,
            "suggested_prompts_mess": suggested_prompts_mess
        }
    
    except Exception as e:
        print(f"ERROR: Image search error: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            "response": f"âš ï¸ Lá»—i xá»­ lÃ½ áº£nh: {str(e)}. Vui lÃ²ng thá»­ láº¡i.",
            "products": [],
            "success": False,
        }
    
    finally:
        if os.path.exists(file_path):
            try:
                os.remove(file_path)
            except:
                pass

@router.post("/classify-products", tags=["Classifyapi"])
def classify_pending_products():
    try:
        conn = get_db()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # Get unclassified products
        cur.execute("""
            SELECT headcode, id_sap, product_name 
            FROM products_qwen 
            WHERE category = 'ChÆ°a phÃ¢n loáº¡i' 
                OR sub_category = 'ChÆ°a phÃ¢n loáº¡i'
                OR material_primary = 'ChÆ°a xÃ¡c Ä‘á»‹nh'
            LIMIT 100
        """)
        
        pending_products = cur.fetchall()
        
        if not pending_products:
            conn.close()
            return {
                "message": "âœ… Táº¥t cáº£ sáº£n pháº©m Ä‘Ã£ Ä‘Æ°á»£c phÃ¢n loáº¡i!",
                "classified": 0,
                "total": 0,
                "remaining": 0
            }
        
        total_pending = len(pending_products)
        classified = 0
        errors = []
        
        BATCH_SIZE = 8  # Gemini handles well with 5-10 items
        
        for i in range(0, len(pending_products), BATCH_SIZE):
            batch = pending_products[i:i+BATCH_SIZE]
            
            # Prepare input for batch classification
            batch_input = [{
                'id_sap': p['id_sap'],
                'name': p['product_name']
            } for p in batch]
            
            print(f"INFO: Classifying batch {i//BATCH_SIZE + 1} ({len(batch)} products)...")
            
            try:
                # CALL BATCH CLASSIFICATION
                results = batch_classify_products(batch_input)
                
                # Update to DB
                for j, result in enumerate(results):
                    try:
                        cur.execute("""
                            UPDATE products_qwen 
                            SET category = %s,
                                sub_category = %s,
                                material_primary = %s,
                                updated_at = NOW()
                            WHERE headcode = %s
                        """, (
                            result['category'],
                            result['sub_category'],
                            result['material_primary'],
                            batch[j]['headcode']
                        ))
                        classified += 1
                    except Exception as e:
                        errors.append(f"{batch[j]['headcode']}: {str(e)[:50]}")
                conn.commit()
                # Delay between batches to avoid rate limit
                if i + BATCH_SIZE < len(pending_products):
                    time.sleep(4)
                
            except Exception as e:
                print(f"ERROR: Batch {i//BATCH_SIZE + 1} failed: {e}")
                errors.append(f"Batch {i//BATCH_SIZE + 1}: {str(e)[:100]}")
                # Continue with next batch
                continue
        
        conn.close()
        
        # Check how many remain unclassified
        conn = get_db()
        cur = conn.cursor()
        cur.execute("""
            SELECT COUNT(*) FROM products_qwen 
            WHERE category = 'ChÆ°a phÃ¢n loáº¡i' 
            OR sub_category = 'ChÆ°a phÃ¢n loáº¡i'
            OR material_primary = 'ChÆ°a xÃ¡c Ä‘á»‹nh'
        """)
        remaining = cur.fetchone()[0]
        conn.close()
        
        return {
            "message": f"âœ… ÄÃ£ phÃ¢n loáº¡i {classified}/{total_pending} sáº£n pháº©m",
            "classified": classified,
            "total": total_pending,
            "remaining": remaining,
            "errors": errors[:10] if errors else []
        }
        
    except Exception as e:
        return {
            "message": f"âŒ Lá»—i: {str(e)}",
            "classified": 0,
            "total": 0,
            "remaining": 0
        }

@router.post("/classify-materials", tags=["Classifyapi"])
def classify_pending_materials():
    """
    ðŸ¤– PhÃ¢n loáº¡i HÃ€NG LOáº T cÃ¡c váº­t liá»‡u chÆ°a phÃ¢n loáº¡i
    """
    try:
        conn = get_db()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        cur.execute(f"""
            SELECT id_sap, material_name, material_group
            FROM {settings.MATERIALS_TABLE} 
            WHERE material_subgroup = 'ChÆ°a phÃ¢n loáº¡i'
            LIMIT 100
        """)
        
        pending_materials = cur.fetchall()
        
        if not pending_materials:
            conn.close()
            return {
                "message": "âœ… Táº¥t cáº£ váº­t liá»‡u Ä‘Ã£ Ä‘Æ°á»£c phÃ¢n loáº¡i!",
                "classified": 0,
                "total": 0,
                "remaining": 0
            }
        
        total_pending = len(pending_materials)
        classified = 0
        errors = []
        
        BATCH_SIZE = 10
        
        for i in range(0, len(pending_materials), BATCH_SIZE):
            batch = pending_materials[i:i+BATCH_SIZE]
            
            batch_input = [{
                'id_sap': m['id_sap'],
                'name': m['material_name']
            } for m in batch]
            
            print(f"BOT: Classifying materials batch {i//BATCH_SIZE + 1} ({len(batch)} items)...")
            
            try:
                results = batch_classify_materials(batch_input)
                
                for j, result in enumerate(results):
                    try:
                        cur.execute("""
                            UPDATE materials 
                            SET material_subgroup = %s,
                                updated_at = NOW()
                            WHERE id_sap = %s
                        """, (
                            result['material_subgroup'],
                            batch[j]['id_sap']
                        ))
                        classified += 1
                    except Exception as e:
                        errors.append(f"{batch[j]['id_sap']}: {str(e)[:50]}")
                
                conn.commit()
                
                if i + BATCH_SIZE < len(pending_materials):
                    time.sleep(4)
                
            except Exception as e:
                print(f"ERROR: Materials batch {i//BATCH_SIZE + 1} failed: {e}")
                errors.append(f"Batch {i//BATCH_SIZE + 1}: {str(e)[:100]}")
                continue
        
        conn.close()
        
        conn = get_db()
        cur = conn.cursor()
        cur.execute(f"""
            SELECT COUNT(*) FROM {settings.MATERIALS_TABLE} 
            WHERE material_subgroup = 'ChÆ°a phÃ¢n loáº¡i'
        """)
        remaining = cur.fetchone()[0]
        conn.close()
        
        return {
            "message": f"âœ… ÄÃ£ phÃ¢n loáº¡i {classified}/{total_pending} váº­t liá»‡u",
            "classified": classified,
            "total": total_pending,
            "remaining": remaining,
            "errors": errors[:10] if errors else []
        }
        
    except Exception as e:
        return {
            "message": f"âŒ Lá»—i: {str(e)}",
            "classified": 0,
            "total": 0,
            "remaining": 0
        }

@router.post("/search-image-with-text", tags=["Classifyapi"])
async def search_by_image_with_text(
    file: UploadFile = File(...),
    description: str = Form(...),
    session_id: str = Form(default=str(uuid.uuid4()))
):
    file_path = f"./media/temp_{uuid.uuid4()}.jpg"
    try:
        # Read and save uploaded file
        contents = await file.read()
        with open(file_path, "wb") as buffer:
            buffer.write(contents)
        
        # Open image with PIL
        img = Image.open(file_path)
        model = genai.GenerativeModel("gemini-2.5-flash")
        
        # Enhanced prompt that combines image analysis with user's text description
        prompt = f"""
            ROLE
            You are a Senior Interior Materials Analyst at AA Corporation with expertise in analyzing products based on both visual and textual information.

            TASK
            Analyze the provided image AND the user's description to extract comprehensive technical information for database search.

            USER'S DESCRIPTION & REQUIREMENTS:
            {description}

            CHIáº¾N LÆ¯á»¢C Dá»® LIá»†U (DATA STRATEGY)
            Output pháº£i lÃ  má»™t máº£ng chá»©a chÃ­nh xÃ¡c 2 Ä‘á»‘i tÆ°á»£ng (objects):

            Object 1 (Æ¯u tiÃªn): Káº¿t há»£p thÃ´ng tin tá»« hÃ¬nh áº£nh VÃ€ mÃ´ táº£ cá»§a user Ä‘á»ƒ táº¡o tá»« khÃ³a tÃ¬m kiáº¿m chÃ­nh xÃ¡c nháº¥t.
            - Æ¯u tiÃªn cÃ¡c yÃªu cáº§u cá»¥ thá»ƒ tá»« user (mÃ u sáº¯c, kÃ­ch thÆ°á»›c, cháº¥t liá»‡u, phong cÃ¡ch...)
            - Káº¿t há»£p vá»›i Ä‘áº·c Ä‘iá»ƒm ná»•i báº­t tá»« hÃ¬nh áº£nh

            Object 2 (Dá»± phÃ²ng): TÃ¬m kiáº¿m má»Ÿ rá»™ng dá»±a trÃªn danh má»¥c chung.

            HÆ¯á»šNG DáºªN CÃC TRÆ¯á»œNG (FIELDS)
            category: Danh má»¥c sáº£n pháº©m (Gháº¿, BÃ n, Sofa, Tá»§, ÄÃ¨n, GiÆ°á»ng, Ká»‡...)

            visual_description: MÃ´ táº£ chuyÃªn nghiá»‡p káº¿t há»£p:
            - Nhá»¯ng gÃ¬ nhÃ¬n tháº¥y tá»« hÃ¬nh áº£nh
            - YÃªu cáº§u cá»¥ thá»ƒ tá»« mÃ´ táº£ cá»§a user
            - Phong cÃ¡ch, cháº¥t liá»‡u, mÃ u sáº¯c, kÃ­ch thÆ°á»›c...

            search_keywords:
            - Object 1: Tá»« khÃ³a chi tiáº¿t káº¿t há»£p yÃªu cáº§u user + Ä‘áº·c Ä‘iá»ƒm hÃ¬nh áº£nh
            - Object 2: Tá»« khÃ³a tá»•ng quÃ¡t hÆ¡n

            material_detected: Váº­t liá»‡u nhÃ¬n tháº¥y tá»« hÃ¬nh áº£nh hoáº·c Ä‘Æ°á»£c user Ä‘á» cáº­p

            color_tone: MÃ u sáº¯c (tá»« hÃ¬nh áº£nh hoáº·c yÃªu cáº§u cá»§a user)

            user_requirements: TÃ³m táº¯t cÃ¡c yÃªu cáº§u Ä‘áº·c biá»‡t cá»§a user (kÃ­ch thÆ°á»›c, giÃ¡, tÃ­nh nÄƒng...)

            Äá»ŠNH Dáº NG OUTPUT
            Tráº£ vá» JSON array: [ {{...}}, {{...}} ]
            KhÃ´ng dÃ¹ng markdown, khÃ´ng giáº£i thÃ­ch thÃªm.
            NgÃ´n ngá»¯: Tiáº¿ng Viá»‡t.

            VÃ Dá»¤:
            User description: "TÃ´i cáº§n gháº¿ vÄƒn phÃ²ng mÃ u xÃ¡m, cÃ³ tá»±a lÆ°ng cao, giÃ¡ dÆ°á»›i 3 triá»‡u"
            Output: [
                {{
                    "category": "Gháº¿",
                    "visual_description": "Gháº¿ vÄƒn phÃ²ng cÃ´ng thÃ¡i há»c lÆ°ng cao, khung nhá»±a PP Ä‘en káº¿t há»£p lÆ°á»›i thoÃ¡ng khÃ­ mÃ u xÃ¡m. Tay vá»‹n nhá»±a chá»¯ T Ä‘iá»u chá»‰nh Ä‘Æ°á»£c. Äá»‡m ngá»“i bá»c váº£i mÃ u xÃ¡m xá»‘p Ãªm. ChÃ¢n sao 5 cÃ¡nh thÃ©p máº¡ cÃ³ bÃ¡nh xe, cáº§n nÃ¢ng háº¡ khÃ­ nÃ©n. Thiáº¿t káº¿ theo yÃªu cáº§u: mÃ u xÃ¡m, lÆ°ng cao, phÃ¹ há»£p vÄƒn phÃ²ng.",
                    "search_keywords": "gháº¿ vÄƒn phÃ²ng lÆ°ng cao xÃ¡m",
                    "material_detected": "LÆ°á»›i, Nhá»±a PP, ThÃ©p máº¡, Váº£i",
                    "color_tone": "XÃ¡m, Äen",
                    "user_requirements": "MÃ u xÃ¡m, tá»±a lÆ°ng cao, giÃ¡ < 3 triá»‡u"
                }},
                {{
                    "category": "Gháº¿",
                    "visual_description": "Gháº¿ vÄƒn phÃ²ng cÃ´ng thÃ¡i há»c lÆ°ng cao, khung nhá»±a PP Ä‘en káº¿t há»£p lÆ°á»›i thoÃ¡ng khÃ­ mÃ u xÃ¡m. Tay vá»‹n nhá»±a chá»¯ T Ä‘iá»u chá»‰nh Ä‘Æ°á»£c. Äá»‡m ngá»“i bá»c váº£i mÃ u xÃ¡m xá»‘p Ãªm. ChÃ¢n sao 5 cÃ¡nh thÃ©p máº¡ cÃ³ bÃ¡nh xe, cáº§n nÃ¢ng háº¡ khÃ­ nÃ©n.",
                    "search_keywords": "gháº¿ vÄƒn phÃ²ng",
                    "material_detected": "LÆ°á»›i, Nhá»±a PP, ThÃ©p máº¡, Váº£i",
                    "color_tone": "XÃ¡m, Äen",
                    "user_requirements": "MÃ u xÃ¡m, tá»±a lÆ°ng cao, giÃ¡ < 3 triá»‡u"
                }}
            ]

            Báº®T Äáº¦U PHÃ‚N TÃCH HÃŒNH áº¢NH NÃ€Y
        """
        
        # Generate content with both image and prompt
        response = model.generate_content([prompt, img])
        
        if not response.text:
            return {
                "response": "âš ï¸ KhÃ´ng phÃ¢n tÃ­ch Ä‘Æ°á»£c áº£nh vÃ  mÃ´ táº£. Vui lÃ²ng thá»­ láº¡i.",
                "products": []
            }
        
        # Parse AI response
        clean = response.text.strip()
        if "```json" in clean:
            clean = clean.split("```json")[1].split("```")[0].strip()
        elif "```" in clean:
            clean = clean.split("```")[1].split("```")[0].strip()
        try:
            ai_result = json.loads(clean)
        except json.JSONDecodeError as e:
            print(f"JSON Parse Error: {e}")
            return {
                "response": "âš ï¸ Lá»—i phÃ¢n tÃ­ch dá»¯ liá»‡u. Vui lÃ²ng thá»­ láº¡i.",
                "products": [],
                "success": False,
            }
        
        print(f"INFO: AI Image+Text Analysis Result: {ai_result}")
        
        # Extract search parameters from AI result
        search_keywords = ai_result[0].get("search_keywords", "").strip()
        category = ai_result[0].get("category", "")
        user_requirements = ai_result[0].get("user_requirements", "")
        
        # Prepare search text
        if not search_keywords or len(search_keywords) > 50:
            search_text = category
            print(f"INFO: Using category as search term: {search_text}")
        else:
            words = search_keywords.split()[:4]  # Use up to 4 words for better matching
            search_text = " ".join(words)
            print(f"INFO: Using keywords: {search_text}")
        
        # Get secondary keywords if available
        secondary_keywords = ""
        secondary_category = ""
        if len(ai_result) > 1:
            secondary_keywords = ai_result[1].get("search_keywords", "").strip()
            secondary_category = ai_result[1].get("category", "")
        
        # Prepare search parameters
        params = {
            "category": category,
            "keywords_vector": search_text,
            "material_primary": ai_result[0].get("material_detected"),
            "main_keywords": search_keywords,
            "secondary_keywords": secondary_keywords,
            "secondary_category": secondary_category,
            "user_description": description  # Include original user description
        }
        
        print(f"INFO: Search params - Main: {search_keywords}, Secondary: {secondary_keywords}")
        print(f"INFO: User requirements: {user_requirements}")
        
        # Execute search
        search_result = search_products(params, session_id=session_id, disable_fallback=True)
        
        products = search_result.get("products", []) or []
        products_second = search_result.get("products_second", []) or []
        
        print(f"INFO: Search results - Main: {len(products)}, Secondary: {len(products_second)}")
        
        # Validate products against image and text description
        ai_interpretation = ai_result[0].get("visual_description", "").lower()
        description_lower = description.lower()
        
        for product in products:
            product_name = (product.get('product_name') or '').lower()
            category_prod = (product.get('category') or '').lower()
            
            # Check match with AI interpretation and user description
            name_match = any(word in ai_interpretation or word in description_lower 
                            for word in product_name.split() if len(word) > 2)
            category_match = category_prod in ai_interpretation or category_prod in description_lower
            
            if not name_match and not category_match:
                current_score = product.get('base_score', 0.6)
                penalty = 0.2
                product['base_score'] = max(0, current_score - penalty)
                product['mismatch'] = True
                print(f"  âš ï¸ Mismatch penalty for {product.get('headcode')}: {current_score:.3f} -> {product['base_score']:.3f}")
            else:
                product['mismatch'] = False
        
        # Classify products by confidence score
        products_main = [p for p in products if p.get('final_score', 0) >= 0.75]
        products_second_main = [p for p in products_second if p.get('similarity', 0) >= 0.6 and p.get('final_score', 0) < 0.75] if products_second else []
        products_low_confidence = [p for p in products if p.get('similarity', 0) < 0.6]
        
        print(f"INFO: Final results - Main: {len(products_main)}, Secondary: {len(products_second_main)}, Low: {len(products_low_confidence)}")
        
        # Save to chat history
        histories.save_chat_to_histories(
            email="test@gmail.com",
            session_id=session_id,
            question=f"[IMAGE+TEXT] {description[:100]}...",
            answer=f"PhÃ¢n tÃ­ch: {ai_result[0].get('visual_description', '')[:100]}... | TÃ¬m tháº¥y {len(products_main)} sáº£n pháº©m phÃ¹ há»£p vá»›i yÃªu cáº§u, {len(products_second_main)} sáº£n pháº©m phá»¥"
        )
        
        # Build response message
        if products_main or products_second_main:
            response_msg = f"ðŸŽ‰ **PhÃ¢n tÃ­ch hÃ¬nh áº£nh vÃ  yÃªu cáº§u cá»§a báº¡n:**\n\n"
            response_msg += f"ðŸ” **MÃ´ táº£ sáº£n pháº©m:** {ai_result[0].get('visual_description', 'N/A')}\n\n"
            if user_requirements:
                response_msg += f"âœ¨ **YÃªu cáº§u cá»§a báº¡n:** {user_requirements}\n\n"
            
            if products_main:
                response_msg += f"âœ… TÃ´i tÃ¬m tháº¥y **{len(products_main)} sáº£n pháº©m phÃ¹ há»£p** vá»›i yÃªu cáº§u cá»§a báº¡n"
            if products_main and products_second_main:
                response_msg += f"Nhá»¯ng sáº£n pháº©m trÃªn cÃ³ phÃ¹ há»£p vá»›i yÃªu cáº§u cá»§a báº¡n khÃ´ng?. Náº¿u khÃ´ng hÃ£y Ä‘á»ƒ tÃ´i tÃ¬m kiáº¿m thÃªm cho báº¡n"
            
            response_msg += "!"
        if not products_main and products_second_main:
            response_msg = f"ðŸŽ‰ **PhÃ¢n tÃ­ch hÃ¬nh áº£nh vÃ  yÃªu cáº§u cá»§a báº¡n:**\n\n"
            response_msg += f"ðŸ” **MÃ´ táº£ sáº£n pháº©m:** {ai_result[0].get('visual_description', 'N/A')}\n\n"
            if user_requirements:
                response_msg += f"âœ¨ **YÃªu cáº§u cá»§a báº¡n:** {user_requirements}\n\n"
            response_msg += f"âš ï¸ Ráº¥t tiáº¿c, tÃ´i chÆ°a tÃ¬m tháº¥y sáº£n pháº©m hoÃ n toÃ n phÃ¹ há»£p vá»›i yÃªu cáº§u cá»§a báº¡n trong cÆ¡ sá»Ÿ dá»¯ liá»‡u.\n\n"
            # response_msg += f"âœ… TÃ´i tÃ¬m tháº¥y **{len(products_second_main)} sáº£n pháº©m tÆ°Æ¡ng tá»±** vá»›i yÃªu cáº§u cá»§a báº¡n! Báº¡n cÃ³ thá»ƒ tham kháº£o:"
        else:
            response_msg = f"ðŸŽ‰ **PhÃ¢n tÃ­ch hÃ¬nh áº£nh vÃ  yÃªu cáº§u:**\n\n"
            response_msg += f"ðŸ” **MÃ´ táº£:** {ai_result[0].get('visual_description', 'N/A')}\n\n"
            if user_requirements:
                response_msg += f"âœ¨ **YÃªu cáº§u:** {user_requirements}\n\n"
            response_msg += f"âš ï¸ Ráº¥t tiáº¿c, tÃ´i chÆ°a tÃ¬m tháº¥y sáº£n pháº©m hoÃ n toÃ n phÃ¹ há»£p vá»›i yÃªu cáº§u cá»§a báº¡n.\n\n"
            response_msg += f"â­ **Ghi chÃº:** Báº¡n cÃ³ thá»ƒ thá»­ mÃ´ táº£ chi tiáº¿t hÆ¡n hoáº·c Ä‘iá»u chá»‰nh yÃªu cáº§u cá»§a báº¡n."

        tmp = generate_suggested_prompts(
                        "search_product_not_found",
                        {"query": user_requirements}
                    )
        suggested_prompts_mess = format_suggested_prompts(tmp)
        
        return {
            "response": response_msg,
            "products": products_main if products_main else None,
            "products_second": products_second_main if products_second_main else None,
            "products_low_confidence": products_low_confidence[:5] if products_low_confidence else [],
            "ai_interpretation": ai_result[0].get("visual_description", ""),
            "user_requirements": user_requirements,
            "search_method": "image_text_combined_search",
            "confidence_summary": {
                "products_main_count": len(products_main),
                "products_second_count": len(products_second_main),
                "low_confidence_count": len(products_low_confidence)
            },
            "success": True,
            "suggested_prompts_mess": suggested_prompts_mess
        }
    
    except Exception as e:
        print(f"ERROR: Image+Text search error: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            "response": f"âš ï¸ Lá»—i xá»­ lÃ½: {str(e)}. Vui lÃ²ng thá»­ láº¡i.",
            "products": [],
            "success": False,
        }
    
    finally:
        # Clean up temporary file
        if os.path.exists(file_path):
            try:
                os.remove(file_path)
            except:
                pass
